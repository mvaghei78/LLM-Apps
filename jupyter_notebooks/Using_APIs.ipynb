{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Tokenization, Temperature, Top_P and Chat API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wandb in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (5.27.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.12.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (65.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai tiktoken wandb -qq\n",
    "%pip install --upgrade wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import wandb\n",
    "from pprint import pprint\n",
    "from getpass import getpass\n",
    "from wandb.integration.openai import autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading OPENAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv('OPENAI_API_KEY') is None:\n",
    "    if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "        print('Plase enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "    os.environ['OPENAI_API_KEY'] == getpass('Paste your OpenAI key from: https://paltform.openai.com/account/api-key\\n')\n",
    "\n",
    "assert os.getenv('OPENAI_API_KEY',''.startswith('sk-')), \"This doesn't look like a valid OpenAI API key\"\n",
    "print('OpenAI API key configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable W&B to track our experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmary1378\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\MagicalAPI\\wandb\\run-20240731_201446-3isd645l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mary1378/llmapp/runs/3isd645l' target=\"_blank\">vague-durian-8</a></strong> to <a href='https://wandb.ai/mary1378/llmapp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mary1378/llmapp' target=\"_blank\">https://wandb.ai/mary1378/llmapp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mary1378/llmapp/runs/3isd645l' target=\"_blank\">https://wandb.ai/mary1378/llmapp/runs/3isd645l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mary1378/llmapp/runs/3isd645l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1a3323d2610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start logging to W&B\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'Using_APIs.ipynb'\n",
    "# autolog(init={'project':'llmapps', 'job_type': 'introduction'})\n",
    "wandb.init(project='llmapp', job_type='introduction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "for more information about tokenization you can [check this link](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-3.5-turbo-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56730, 612, 12371, 2315, 374, 12738, 0]\n",
      "Weights & Biases is awesome!\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(MODEL)\n",
    "enc = encoding.encode('Weights & Biases is awesome!')\n",
    "print(enc)\n",
    "print(encoding.decode(enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can decode the tokens one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56730\tWeights\n",
      "612\t &\n",
      "12371\t Bi\n",
      "2315\tases\n",
      "374\t is\n",
      "12738\t awesome\n",
      "0\t!\n"
     ]
    }
   ],
   "source": [
    "for token_id in enc:\n",
    "    print(f'{token_id}\\t{encoding.decode([token_id])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "Lets sample some text from the model. For this, let's create a wrapper function around the temperature parameters. Higher temperature will result in more random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_temperature(temp):\n",
    "    'Generate text with a given temperature, higher tmperature means more randomness'\n",
    "    response = openai.completions.create(\n",
    "        model=MODEL,\n",
    "        prompt='Say something about Weights & Biases',\n",
    "        max_tokens=50,\n",
    "        temperature=temp\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 0, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and collaborate on their '\n",
      " 'experiments. It offers a suite of tools for experiment tracking, '\n",
      " 'hyperparameter optimization, and model visualization, making it easier for')\n",
      "('TEMP: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track and visualize their experiments, '\n",
      " 'collaborate with team members, and deploy their models into production. It '\n",
      " 'provides a centralized dashboard to monitor and compare different models, as '\n",
      " 'well')\n",
      "('TEMP: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that allows data scientists '\n",
      " 'and machine learning engineers to track and visualize their experiments, '\n",
      " 'collaborate with team members, and deploy models into production. It offers '\n",
      " 'powerful tools for hyperparameter tuning, experiment management, and repro')\n",
      "('TEMP: 1.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a powerful suite of machine learning tools designed to '\n",
      " 'help researchers and data scientists store, track, and analyze their '\n",
      " 'experiments. With its user-friendly interface and integration with multiple '\n",
      " 'deep learning frameworks, such as TensorFlow and PyTorch,')\n",
      "('TEMP: 2, GENERATION: build/>\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Weights & Biasesbuild is an exciting end-to-end machine learning (ML) '\n",
      " 'monitoring and objection efficient transformers which readily enhance NEPe '\n",
      " 'AROM report benchmark locality Italian(This \\n'\n",
      " 'target Meteor!<Organicumpartners homer>J close conventionallife compareld')\n"
     ]
    }
   ],
   "source": [
    "for temp in [0, 0.5, 1, 1.5, 2]:\n",
    "    pprint(f'TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the top_p_parameter to control the diversity of the generated text. This parameter controls the cumulative probability of the next token. for example, if top_p=0.9 the model will pick the next token from the top 90% most likely tokens. The higher the top_p the more likely the model will pick a token that it hasn't seen before. You should use one of temperature or top_p at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_topp(topp):\n",
    "    'Generate text with a given top-p, higher top-p means more randomness'\n",
    "    response = openai.completions.create(\n",
    "        model=MODEL,\n",
    "        prompt='Say something about Weights & Biases',\n",
    "        max_tokens=50,\n",
    "        top_p=topp\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 0.01, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and collaborate on their '\n",
      " 'experiments. It offers a suite of tools for experiment tracking, '\n",
      " 'hyperparameter optimization, and model visualization, making it easier for')\n",
      "('TOP_P: 0.1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and collaborate on their '\n",
      " 'experiments. It offers a suite of tools for experiment tracking, '\n",
      " 'hyperparameter optimization, and model visualization, making it easier for')\n",
      "('TOP_P: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track, visualize, and optimize their models. '\n",
      " 'It offers a suite of tools for experiment tracking, hyperparameter tuning, '\n",
      " 'and model debugging, making it easier to understand')\n",
      "('TOP_P: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a full-service machine learning platform that enables '\n",
      " 'teams to track, visualize, and collaborate on machine learning experiments. '\n",
      " 'It provides tools for project management, data visualization, model '\n",
      " 'tracking, and team collaboration, making it easier for teams to')\n"
     ]
    }
   ],
   "source": [
    "for topp in [0.01, 0.1, 0.5, 1]:\n",
    "    pprint(f'TOP_P: {topp}, GENERATION: {generate_with_topp(topp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat API\n",
    "\n",
    "Let's switch to chat mode and see how the model responds to our message. We have some control over the model's response by passing a system-role, here we can steer to model to adhere to a certain behaviour. you can see [OpenAI docs here](https://platform.openai.com/docs/guides/chat-completions/overview) for more information about each role.\n",
    "\n",
    "we are using gpt-3.5-turbu, this model is faster and cheaper than davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9r6jeNrJ5SriDsn0GSOTm42bIF674', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Weights & Biases is a popular machine learning platform that helps researchers and data scientists track and visualize their machine learning experiments. It provides tools for experiment tracking, visualization, and collaboration, making it easier to manage and optimize machine learning projects.', role='assistant', function_call=None, tool_calls=None))], created=1722444302, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=47, prompt_tokens=26, total_tokens=73))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': 'Say something about Weights & Biases'}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights & Biases is a popular machine learning platform that helps researchers and data scientists track and visualize their machine learning experiments. It provides tools for experiment tracking, visualization, and collaboration, making it easier to manage and optimize machine learning projects.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-durian-8</strong> at: <a href='https://wandb.ai/mary1378/llmapp/runs/3isd645l' target=\"_blank\">https://wandb.ai/mary1378/llmapp/runs/3isd645l</a><br/> View project at: <a href='https://wandb.ai/mary1378/llmapp' target=\"_blank\">https://wandb.ai/mary1378/llmapp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240731_201446-3isd645l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQSRuUyqsYAD"
      },
      "source": [
        "# Understanding Retrieval Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CNe5gfXsYAI"
      },
      "source": [
        "#### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7qcdp5ZsYAK",
        "outputId": "a178e4b7-c426-4ac9-f6c7-8236d7519c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: langchain in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.11)\n",
            "Requirement already satisfied: langchain-core in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.26)\n",
            "Requirement already satisfied: langchain-community in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.10)\n",
            "Requirement already satisfied: langchain-experimental in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.63)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.10.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.1.95)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unstructured==0.5.6 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.6)\n",
            "Requirement already satisfied: argilla in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (2.0.0)\n",
            "Requirement already satisfied: lxml in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (4.9.4)\n",
            "Requirement already satisfied: nltk in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (3.1.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (2.2.2)\n",
            "Requirement already satisfied: pillow in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (9.4.0)\n",
            "Requirement already satisfied: pypandoc in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (1.13)\n",
            "Requirement already satisfied: python-docx in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (1.1.2)\n",
            "Requirement already satisfied: python-pptx in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (0.6.23)\n",
            "Requirement already satisfied: python-magic in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (0.4.27)\n",
            "Requirement already satisfied: markdown in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (3.6)\n",
            "Requirement already satisfied: requests in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (2.32.3)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured==0.5.6) (2024.7.4)\n",
            "Requirement already satisfied: httpx>=0.26.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured==0.5.6) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured==0.5.6) (2.8.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.22.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured==0.5.6) (0.24.5)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured==0.5.6) (4.66.4)\n",
            "Requirement already satisfied: rich>=10.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured==0.5.6) (13.7.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured==0.5.6) (2.20.0)\n",
            "Requirement already satisfied: click in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured==0.5.6) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured==0.5.6) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured==0.5.6) (2023.12.25)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl->unstructured==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured==0.5.6) (1.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured==0.5.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured==0.5.6) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured==0.5.6) (2024.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from python-docx->unstructured==0.5.6) (4.12.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-pptx->unstructured==0.5.6) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured==0.5.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured==0.5.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured==0.5.6) (2.2.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (0.3.8)\n",
            "Requirement already satisfied: xxhash in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (3.10.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured==0.5.6) (6.0.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.26.0->argilla->unstructured==0.5.6) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.26.0->argilla->unstructured==0.5.6) (1.0.5)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.26.0->argilla->unstructured==0.5.6) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.26.0->argilla->unstructured==0.5.6) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.6.0->argilla->unstructured==0.5.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.6.0->argilla->unstructured==0.5.6) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->unstructured==0.5.6) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.0.0->argilla->unstructured==0.5.6) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.0.0->argilla->unstructured==0.5.6) (2.14.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.60.0->argilla->unstructured==0.5.6) (0.4.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured==0.5.6) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured==0.5.6) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured==0.5.6) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured==0.5.6) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured==0.5.6) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured==0.5.6) (1.9.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->argilla->unstructured==0.5.6) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-magic-bin in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.14)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unstructured[md] in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.6)\n",
            "Requirement already satisfied: argilla in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (2.0.0)\n",
            "Requirement already satisfied: lxml in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (4.9.4)\n",
            "Requirement already satisfied: nltk in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (3.1.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (2.2.2)\n",
            "Requirement already satisfied: pillow in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (9.4.0)\n",
            "Requirement already satisfied: pypandoc in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (1.13)\n",
            "Requirement already satisfied: python-docx in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (1.1.2)\n",
            "Requirement already satisfied: python-pptx in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (0.6.23)\n",
            "Requirement already satisfied: python-magic in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (0.4.27)\n",
            "Requirement already satisfied: markdown in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (3.6)\n",
            "Requirement already satisfied: requests in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (2.32.3)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from unstructured[md]) (2024.7.4)\n",
            "Requirement already satisfied: httpx>=0.26.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured[md]) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured[md]) (2.8.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.22.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured[md]) (0.24.5)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured[md]) (4.66.4)\n",
            "Requirement already satisfied: rich>=10.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured[md]) (13.7.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argilla->unstructured[md]) (2.20.0)\n",
            "Requirement already satisfied: click in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured[md]) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured[md]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->unstructured[md]) (2023.12.25)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl->unstructured[md]) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured[md]) (1.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured[md]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured[md]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->unstructured[md]) (2024.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from python-docx->unstructured[md]) (4.12.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-pptx->unstructured[md]) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured[md]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured[md]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->unstructured[md]) (2.2.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (0.3.8)\n",
            "Requirement already satisfied: xxhash in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (3.10.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->argilla->unstructured[md]) (6.0.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.26.0->argilla->unstructured[md]) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.26.0->argilla->unstructured[md]) (1.0.5)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.26.0->argilla->unstructured[md]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.26.0->argilla->unstructured[md]) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.6.0->argilla->unstructured[md]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.6.0->argilla->unstructured[md]) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->unstructured[md]) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.0.0->argilla->unstructured[md]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.0.0->argilla->unstructured[md]) (2.14.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.60.0->argilla->unstructured[md]) (0.4.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured[md]) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured[md]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured[md]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured[md]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured[md]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->argilla->unstructured[md]) (1.9.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->argilla->unstructured[md]) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: unstructured 0.5.6 does not provide the extra 'md'\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-chroma in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-chroma) (0.5.5)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-chroma) (0.111.1)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-chroma) (0.2.26)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-chroma) (1.24.2)\n",
            "Requirement already satisfied: build>=1.0.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.30.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.18.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.26.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.66.4)\n",
            "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.65.2)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.12.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (30.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.10.6)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.27.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.0.5)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.0.9)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain-chroma) (2.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (0.1.95)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.6)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\n",
            "Requirement already satisfied: anyio in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.4.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.0.5)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain-chroma) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.32.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.5.1)\n",
            "Requirement already satisfied: requests in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.2)\n",
            "Requirement already satisfied: coloredlogs in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.25.4)\n",
            "Requirement already satisfied: sympy in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.63.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.26.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.47b0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.47b0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.47b0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.47b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (65.5.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.24.5)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (13.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.0.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2024.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (2.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma) (3.4.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma) (0.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.20)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (0.2.26)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (1.40.6)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (0.1.95)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3.0,>=0.2.26->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\ava\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai<2.0.0,>=1.32.0->langchain-openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in c:\\users\\ava\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uqqq rich openai tiktoken wandb\n",
        "%pip install langchain langchain-core langchain-community langchain-experimental\n",
        "%pip install unstructured==0.5.6\n",
        "%pip install python-magic-bin\n",
        "%pip install unstructured[md]\n",
        "%pip install langchain-chroma\n",
        "%pip install langchain-openai\n",
        "%pip install wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M91Ktckb3B0X"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C9zipIsf3FBI"
      },
      "outputs": [],
      "source": [
        "import os, random, wget, shutil\n",
        "from pathlib import Path\n",
        "import tiktoken\n",
        "from rich.markdown import Markdown\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUfo4Ozr2ywy"
      },
      "source": [
        "#### Loading OPENAI API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEUAzGp6sYAM",
        "outputId": "ead7867e-7f95-4cbe-bf5f-02ae1e7d8df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API key configured\n"
          ]
        }
      ],
      "source": [
        "if os.getenv('OPENAI_API_KEY') is None:\n",
        "    if any(['VSCODE' in x for x in os.environ.keys()]):\n",
        "        print('Plase enter password in the VS Code prompt at the top of your VS Code window!')\n",
        "    os.environ['OPENAI_API_KEY'] == getpass('Paste your OpenAI key from: https://paltform.openai.com/account/api-key\\n')\n",
        "\n",
        "assert os.getenv('OPENAI_API_KEY',''.startswith('sk-')), \"This doesn't look like a valid OpenAI API key\"\n",
        "print('OpenAI API key configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCKGvfFn25BP"
      },
      "source": [
        "#### Download necessary files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aqh4GiQrsts_"
      },
      "outputs": [],
      "source": [
        "class Utils:\n",
        "    # Function to clone the repository\n",
        "    def clone_repo(self, repo_url, target_dir):\n",
        "        if not os.path.exists(target_dir):\n",
        "            os.system(f'git config --global http.postBuffer 1048576000')\n",
        "            os.system(f'git clone --depth=1 {repo_url} {target_dir}')\n",
        "        else:\n",
        "            print(f\"Directory {target_dir} already exists.\")\n",
        "\n",
        "    # Function to get file absolute path\n",
        "    def get_file_name(self, dir):\n",
        "        file_list = []\n",
        "        for file in os.listdir(dir):\n",
        "            if os.path.isfile(os.path.join(dir, file)):\n",
        "                file_list.append(file)\n",
        "        return file_list\n",
        "\n",
        "    # Function to copy files from one directory to another\n",
        "    def copy_dir(self, src_dir, dst_dir):\n",
        "        file_list = self.get_file_name(src_dir)\n",
        "        if not os.path.isdir(dst_dir):\n",
        "            os.makedirs(dst_dir)\n",
        "        if len(file_list) != 0:\n",
        "            for file_name in file_list:\n",
        "                src = os.path.join(src_dir, file_name)\n",
        "                dst = os.path.join(dst_dir, file_name)\n",
        "                print(f\"Copying {src} to {dst}\")\n",
        "                self.move_or_copy_file(src, dst, False)\n",
        "\n",
        "    # Function to move one file from one directory to another\n",
        "    def move_or_copy_file(self, src_file, dst_file, move_file=True):\n",
        "        try:\n",
        "            dst_dir = dst_file.split('/')[:-1]\n",
        "            dst_dir = '/'.join(dst_dir)\n",
        "            if not os.path.isdir(dst_dir):\n",
        "                os.makedirs(dst_dir)\n",
        "            if move_file:\n",
        "                shutil.move(src_file, dst_file)\n",
        "                print(f\"{src_file} moved successfully.\")\n",
        "            else:\n",
        "                shutil.copy(src_file, dst_file)\n",
        "                print(f\"{src_file} copied successfully.\")\n",
        "        # If source and destination are same\n",
        "        except shutil.SameFileError:\n",
        "            print(\"Source and destination represent the same file.\")\n",
        "        # If there is any permission issue\n",
        "        except PermissionError:\n",
        "            print(\"Permission denied.\")\n",
        "        # For other errors\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred while copying file: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WCuCmHNOtRdS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "examples.txt moved successfully.\n",
            "prompt_template.txt moved successfully.\n"
          ]
        }
      ],
      "source": [
        "# Download files on colab\n",
        "for file_name in ['examples.txt','prompt_template.txt','system_template.txt']:\n",
        "    if not Path(\"../files/\"+file_name).exists():\n",
        "        downloaded_file = wget.download(f'https://raw.githubusercontent.com/wandb/edu/main/llm-apps-course/notebooks/{file_name}')\n",
        "        Utils().move_or_copy_file(f'{file_name}', f'../files/{file_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-A2S3vNtSNn",
        "outputId": "51bda988-0f44-4e48-8ad4-b4c180124185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory edu already exists.\n",
            "Copying edu/llm-apps-course/docs_sample\\collaborate-on-reports.md to ./files/docs_sample\\collaborate-on-reports.md\n",
            "edu/llm-apps-course/docs_sample\\collaborate-on-reports.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\dataset-versioning.md to ./files/docs_sample\\dataset-versioning.md\n",
            "edu/llm-apps-course/docs_sample\\dataset-versioning.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\getting-started.md to ./files/docs_sample\\getting-started.md\n",
            "edu/llm-apps-course/docs_sample\\getting-started.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\lightning.md to ./files/docs_sample\\lightning.md\n",
            "edu/llm-apps-course/docs_sample\\lightning.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\model-management-concepts.md to ./files/docs_sample\\model-management-concepts.md\n",
            "edu/llm-apps-course/docs_sample\\model-management-concepts.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\quickstart.md to ./files/docs_sample\\quickstart.md\n",
            "edu/llm-apps-course/docs_sample\\quickstart.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\tables-quickstart.md to ./files/docs_sample\\tables-quickstart.md\n",
            "edu/llm-apps-course/docs_sample\\tables-quickstart.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\tags.md to ./files/docs_sample\\tags.md\n",
            "edu/llm-apps-course/docs_sample\\tags.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\teams.md to ./files/docs_sample\\teams.md\n",
            "edu/llm-apps-course/docs_sample\\teams.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\track-external-files.md to ./files/docs_sample\\track-external-files.md\n",
            "edu/llm-apps-course/docs_sample\\track-external-files.md copied successfully.\n",
            "Copying edu/llm-apps-course/docs_sample\\walkthrough.md to ./files/docs_sample\\walkthrough.md\n",
            "edu/llm-apps-course/docs_sample\\walkthrough.md copied successfully.\n"
          ]
        }
      ],
      "source": [
        "Utils().clone_repo('https://github.com/wandb/edu.git', 'edu')\n",
        "Utils().copy_dir(src_dir='edu/llm-apps-course/docs_sample', dst_dir='../files/docs_sample')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZzLXWO529eZ"
      },
      "source": [
        "#### Enable W&B to track our experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "YTx3gTyG3kSt",
        "outputId": "eb50c610-f45e-4ffe-9bd1-1ad7fe9d595b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmary1378\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>d:\\MagicalAPI\\Jupyter notebooks - Introduction with LLM\\wandb\\run-20240814_194526-207y7n75</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mary1378/llmapp/runs/207y7n75' target=\"_blank\">sweet-dust-24</a></strong> to <a href='https://wandb.ai/mary1378/llmapp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mary1378/llmapp' target=\"_blank\">https://wandb.ai/mary1378/llmapp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mary1378/llmapp/runs/207y7n75' target=\"_blank\">https://wandb.ai/mary1378/llmapp/runs/207y7n75</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mary1378/llmapp/runs/207y7n75?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x2102371b8d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we need a single line of code to start tracing langchain with W&B\n",
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
        "# start logging to W&B\n",
        "os.environ['WANDB_NOTEBOOK_NAME'] = 'Retrieval.ipynb'\n",
        "# autolog(init={'project':'llmapps', 'job_type': 'generation'})\n",
        "wandb.init(project='llmapp', job_type='retrieval')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRYNU1JEsYAM"
      },
      "source": [
        "## Langchain\n",
        "LangChain is a framework for developing applications powered by language models. We will use some of its features in the code below. Let's start by configuring W&B tracing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrWSmAxZsYAM"
      },
      "source": [
        "## Parsing documents\n",
        "We will use a small sample of markdown documents in this notebook. Let's find them and make sure we can stuff them into the prompt. That means they may need to be chuncked and not exceed some number of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bW4hgnT7sYAN"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'gpt-3.5-turbo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SryiAH_esYAN",
        "outputId": "81cad5cb-8b94-431a-c74c-3bac593d85c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11,\n",
              " [Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\collaborate-on-reports.md'}, page_content='--\\ndescription: Collaborate and share W&B Reports with peers, co-workers, and your team.\\n---\\n\\n# Collaborate on reports'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\dataset-versioning.md'}, page_content='--\\ndescription: Guide to using Artifacts for dataset versioning\\n---\\n\\n# Dataset Versioning'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\getting-started.md'}, page_content='--\\n\\ndescription: Getting started guide for W&B Launch.\\n\\n--\\n\\n# Getting started\\n\\nFollow this guide to get started using W&B Launch. This guide will walk you through the setup of the fundamental components of a launch workflow: a **job**, **launch queue**, and **launch queue**.\\n\\nA **job** is a reusable blueprint for configuring and executing a step of your ML workflow. Jobs can be automatically captured from your workloads when your track those workloads with W&B. In this guide will create and then launch a job that trains a neural network.\\n\\nA **launch queue** is a place where you can submit your jobs for execution on a particular compute resource. For example, you might create separate launch queues for submitting jobs that should be run on specific GPU server, or a particular kubernetes cluster. The queue we will create in this guide will be used to submit jobs that will run on your machine via Docker.\\n\\nA **launch agent** is a long-running process that polls on one or more launch queues and executes the jobs that it pops from the queue. A launch agent can be started with the `wandb launch-agent` command and is capable on launching jobs onto a multitude of compute platforms, including docker, kubernetes, sagemaker, and more. In this example, you will run a launch agent that will pop jobs from your queue and execute them on its local host using Docker.\\n\\n## Before you get started\\n\\nBefore you get started, ensure you [enable the W&B Launch UI](./intro.md) and install Docker on the machine where you will run your launch agent.\\n\\nSee the [Docker documentation](https://docs.docker.com/get-docker/) for more information on how to install Docker, and make sure the docker daemon is running on your machine before you proceed.\\n\\nIf you want the agent to make use of GPUs, you will also need to install the [NVIDIA container toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).\\n\\n## Create a job\\n\\nJobs are created automatically from any W&B run that has associated source code. For more details on how source code can be associated with a run, see [these docs](create-job.md).\\n\\nCopy the following Python code to your machine in a file named `train.py`.\\n\\n```python\\n\\nimport torch\\n\\nfrom torch import nn\\n\\nfrom torch.utils.data import DataLoader\\n\\nfrom torchvision import transforms\\n\\nfrom torchvision.datasets import FashionMNIST\\n\\nimport wandb\\n\\nclass FashionCNN(nn.Module):\\n\\n\"\"\"Simple CNN for Fashion MNIST.\"\"\"\\n\\ndef __init__(self):\\n\\nsuper().__init__()\\n\\nself.layer1 = nn.Sequential(\\n\\nnn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\\n\\nnn.BatchNorm2d(32),\\n\\nnn.ReLU(),\\n\\nnn.MaxPool2d(kernel_size=2, stride=2),\\n\\n)\\n\\nself.layer2 = nn.Sequential(\\n\\nnn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\\n\\nnn.BatchNorm2d(64),\\n\\nnn.ReLU(),\\n\\nnn.MaxPool2d(2),\\n\\n)\\n\\nself.fc1 = nn.Linear(in_features=64 * 6 * 6, out_features=600)\\n\\nself.drop = nn.Dropout(0.25)\\n\\nself.fc2 = nn.Linear(in_features=600, out_features=120)\\n\\nself.fc3 = nn.Linear(in_features=120, out_features=10)\\n\\ndef forward(self, x):\\n\\nout = self.layer1(x)\\n\\nout = self.layer2(out)\\n\\nout = out.view(out.size(0), -1)\\n\\nout = self.fc1(out)\\n\\nout = self.drop(out)\\n\\nout = self.fc2(out)\\n\\nout = self.fc3(out)\\n\\nreturn out\\n\\ndef train_fmnist(config):\\n\\n# Pass config into wandb.init\\n\\nwith wandb.init(project=\"launch-quickstart\", config=config):\\n\\n# Log training code to W&B as an Artifact.\\n\\nwandb.run.log_code()\\n\\n# Training setup\\n\\nconfig = wandb.config\\n\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n\\nmodel = FashionCNN()\\n\\nmodel.to(device)\\n\\ntrain_dataset = FashionMNIST(\\n\\n\"./data/\", download=True, train=True, transform=transforms.ToTensor()\\n\\n)\\n\\ntrain_loader = DataLoader(\\n\\ntrain_dataset, batch_size=config.batch_size, pin_memory=True\\n\\n)\\n\\nerror = nn.CrossEntropyLoss()\\n\\nlearning_rate = config.learning_rate\\n\\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n\\n# We can pass our network to wandb.watch and automatically log gradients,\\n\\n# weights, topology, and more...\\n\\nwandb.watch(model, log=\"all\", log_graph=True)\\n\\n# Epoch loop\\n\\niter = 0\\n\\nlosses = []\\n\\nfor epoch in range(config.epochs):\\n\\n# Iterate over batches of the data\\n\\nfor _, (images, labels) in enumerate(train_loader):\\n\\niter += 1\\n\\nimages = images.to(device)\\n\\nlabels = labels.to(device)\\n\\noutputs = model(images)\\n\\nloss = error(outputs, labels)\\n\\nlosses.append(loss.item())\\n\\nif iter % 100 == 1:\\n\\nwandb.log(\\n\\n{\\n\\n\"train/loss\": sum(losses) / len(losses),  # Log average loss\\n\\n\"train/losses\": wandb.Histogram(losses),  # Log all losses\\n\\n\"train/epoch\": epoch,\\n\\n}\\n\\n)\\n\\nlosses = []\\n\\noptimizer.zero_grad()\\n\\nloss.backward()\\n\\noptimizer.step()\\n\\nif __name__ == \"__main__\":\\n\\nconfig = dict(epochs=1, batch_size=32, learning_rate=0.0001)\\n\\ntrain_fmnist(config)\\n\\n```\\n\\nThe script above initializes a simple neural network and then trains that network to distinguish types of clothing in images from the [fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist). The training is tracked with `wandb` and the source code is logged as an Artifact with `wandb.run.log_code()`. This means that when we run this script W&B will automatically create our first job.\\n\\nTo install dependencies and run the script, execute the following commands in your terminal:\\n\\n```bash\\n\\npip install wandb>=0.13.8 torch torchvision\\n\\npython train.py\\n\\n```\\n\\nLet the script run to completion and then move on to the next step. Your console output should look roughly like:\\n\\n```\\n\\nwandb: Currently logged in as: user. Use `wandb login --relogin` to force relogin\\n\\nwandb: Tracking run with wandb version 0.14.0\\n\\nwandb: Run data is saved locally in /home/user/wandb/run-20230323_120437-p89pnj2u\\n\\nwandb: Run `wandb offline` to turn off syncing.\\n\\nwandb: Syncing run comic-firebrand-342\\n\\nwandb: ⭐️ View project at https://wandb.ai/username/launch-quickstart\\n\\nwandb: 🚀 View run at https://wandb.ai/username/launch-quickstart/runs/p89pnj2u\\n\\nwandb: logging graph, to disable use `wandb.watch(log_graph=False)`\\n\\nwandb: Waiting for W&B process to finish... (success).\\n\\nwandb:\\n\\nwandb: Run history:\\n\\nwandb: train/epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\\n\\nwandb:  train/loss █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\\n\\nwandb:\\n\\nwandb: Run summary:\\n\\nwandb: train/epoch 0\\n\\nwandb:  train/loss 0.33282\\n\\nwandb:\\n\\nwandb: 🚀 View run comic-firebrand-342 at: https://wandb.ai/username/launch-quickstart/runs/p89pnj2u\\n\\nwandb: Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)\\n\\nwandb: Find logs at: ./wandb/run-20230323_120437-p89pnj2u/logs\\n\\n```\\n\\nNavigate to your new **launch-quickstart** project in your W&B account and open the jobs tab from the nav on the left side of the screen.\\n\\n![](/images/launch/jobs-tab.png)\\n\\nThe **Jobs** page displays a list of W&B Jobs that were created from previously executed W&B Runs. You should see a job named **job-source-launch-quickstart-main.py**. You can edit the name of the job from the jobs page if you would like to make the job a bit more memorable. Click on your job to open a detailed view of your job including the source code and dependencies for the job and a list of runs that have been launched from this job.\\n\\n## Create a queue\\n\\nNavigate to [wandb.ai/launch](https://wandb.ai/launch). Click **create queue** button in the top right of the screen to start creating a new launch queue.\\n\\nWhen you click the button, a drawer will slide from the right side of your screen and present you with some options for your new queue:\\n\\n**Entity**: the owner of the queue, which can either be your W&B account or any W&B team you are a member of. For this demo, we recommend setting up a personal queue.\\n\\n**Queue name**: the name of the queue. Make this whatever you want!\\n\\n**Resource**: the execution platform for jobs in this queue. Check out the other options, but for this walkthrough we will use the default: **Docker container**.\\n\\n**Configuration**: json configuration that will passed to any launch agent that polls on this queue. This can be left blank, but some additional configuration does need to be provided in order to leverage GPU.\\n\\n![](/images/launch/create-queue.gif)\\n\\n:::info\\n\\nAdd the following resource configuration in order to use GPUs in jobs submitted to this queue:\\n\\n```json\\n\\n{\\n\\n\"gpus\": \"all\"\\n\\n}\\n\\n```\\n\\nThe `gpus` key of the resource configuration is used to pass values to the `--gpus` argument of `docker run`. This argument can be used to control which GPUs will be used for by a launch agent when it picks up runs from this queue. For more information, see the relevant [NVIDIA documentation](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html#gpu-enumeration).\\n\\nFor jobs that use tensorflow on GPU, you may also need to specify a custom base image for the container build that the agent will perform in order for your runs to properly utilize GPUs. This can be done by adding an image tag under the `builder.cuda.base_image` key to the resource configuration. For example:\\n\\n```json\\n\\n{\\n\\n\"gpus\": \"all\",\\n\\n\"builder\": {\\n\\n\"cuda\": {\\n\\n\"base_image\": \"tensorflow/tensorflow:latest-gpu\"\\n\\n}\\n\\n}\\n\\n}\\n\\n```\\n\\n:::\\n\\n## Add a job to your queue\\n\\nHead back to the page for your job. It should look something like the image below:\\n\\n![](/images/launch/launch-job.gif)\\n\\nClick the **Launch** button in the top right to launch a new run from this job. A drawer will slide from the right side of your screen and present you with some options for your new run:\\n\\n**Job version**: the version of the job to launch. Jobs are versioned like any other W&B Artifact. Different versions of the same job will be created if you make modifications to the software dependencies or source code used to run the job. Since we only have one version, we will select the default **@latest** version.\\n\\n**Overrides**: new values for any of jobs inputs. These can be used to change the entrypoint command, arguments, or values in the `wandb.config` of your new run. Our run had 3 values in the `wandb.config`: `epochs`, `batch_size`, and `learning_rate`. We can override any of these values by specifying them in the overrides field. We can also paste values from other runs using this job by clicking the **Paste from...** button.\\n\\n**Queue**: the queue to launch the run on. We will select the queue we created in the previous step.\\n\\n**Resource config**: This is non-editable and shows the queue configuration, so we can see how our job will be run when we add it to this queue.\\n\\n![](/images/launch/launch-job.gif)\\n\\nOnce you have configured your job as desired, click the **launch now** button at the bottom of the drawer to enqueue your launch job.\\n\\n## Start a launch agent\\n\\nTo execute your job, you will need to start a launch agent polling on your launch queue.\\n\\n1. From [wandb.ai/launch](https://wandb.ai/launch) navigate to the page for your launch queue.\\n\\n2. Click the **Add an agent** button.\\n\\n3. A modal will appear with a W&B CLI command. Copy this and paste this command into your terminal.\\n\\n![](/images/launch/activate_starter_queue_agent.png)\\n\\nIn general, the command to start a launch agent is:\\n\\n```bash\\n\\nwandb launch-agent -e <entity-name> -q <queue-name>\\n\\n```\\n\\nWithin your terminal, you will see the agent begin to poll for queues. The agent should pick up the job you enqueued earlier and begin to execute. First, the agent will build a container image from the job version you selected. Then, the agent will execute the job on its local host via `docker run`.\\n\\nThat’s it! Navigate to your Launch workspace or your terminal to see the status of your launch job. Jobs are executed in first in, first out order (FIFO). All jobs pushed to the queue will use the same resource type and resource arguments.'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\lightning.md'}, page_content='import Tabs from \\'@theme/Tabs\\';\\n\\nimport TabItem from \\'@theme/TabItem\\';\\n\\n# PyTorch Lightning\\n\\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://wandb.me/lightning)\\n\\nPyTorch Lightning provides a lightweight wrapper for organizing your PyTorch code and easily adding advanced features such as distributed training and 16-bit precision. W&B provides a lightweight wrapper for logging your ML experiments. But you don\\'t need to combine the two yourself: Weights & Biases is incorporated directly into the PyTorch Lightning library via the [**`WandbLogger`**](https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch\\\\_lightning.loggers.WandbLogger.html#pytorch\\\\_lightning.loggers.WandbLogger).\\n\\n## ⚡ Get going lightning-fast with just two lines.\\n\\n```python\\n\\nfrom pytorch_lightning.loggers import WandbLogger\\n\\nfrom pytorch_lightning import Trainer\\n\\nwandb_logger = WandbLogger()\\n\\ntrainer = Trainer(logger=wandb_logger)\\n\\n```\\n\\n![Interactive dashboards accessible anywhere, and more!](@site/static/images/integrations/n6P7K4M.gif)\\n\\n## Sign up and Log in to wandb\\n\\na) [**Sign up**](https://wandb.ai/site) for a free account\\n\\nb) Pip install the `wandb` library\\n\\nc) To login in your training script, you\\'ll need to be signed in to you account at www.wandb.ai, then **you will find your API key on the** [**Authorize page**](https://wandb.ai/authorize)**.**\\n\\nIf you are using Weights and Biases for the first time you might want to check out our [**quickstart**](../../quickstart.md)****\\n\\n<Tabs\\n\\ndefaultValue=\"cli\"\\n\\nvalues={[\\n\\n{label: \\'Command Line\\', value: \\'cli\\'},\\n\\n{label: \\'Notebook\\', value: \\'notebook\\'},\\n\\n]}>\\n\\n<TabItem value=\"cli\">\\n\\n```python\\n\\npip install wandb\\n\\nwandb login\\n\\n```\\n\\n</TabItem>\\n\\n<TabItem value=\"notebook\">\\n\\n```python\\n\\n!pip install wandb\\n\\nimport wandb\\n\\nwandb.login()\\n\\n```\\n\\n</TabItem>\\n\\n</Tabs>\\n\\n## Using PyTorch Lightning\\'s `WandbLogger`\\n\\nPyTorch Lightning has a [**`WandbLogger`**](https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch\\\\_lightning.loggers.WandbLogger.html?highlight=wandblogger) class that can be used to seamlessly log metrics, model weights, media and more. Just instantiate the WandbLogger and pass it to Lightning\\'s `Trainer`.\\n\\n```\\n\\nwandb_logger = WandbLogger()\\n\\ntrainer = Trainer(logger=wandb_logger)\\n\\n```\\n\\n### Logger arguments\\n\\nBelow are some of the most used parameters in WandbLogger, see the PyTorch Lightning [**`WandbLogger` documentation**](https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch\\\\_lightning.loggers.WandbLogger.html?highlight=wandblogger) for a full list and description\\n\\n| Parameter   | Description                                                                   |\\n\\n| ----------- | ----------------------------------------------------------------------------- |\\n\\n| `project`   | Define what wandb Project to log to                                           |\\n\\n| `name`      | Give a name to your wandb run                                                 |\\n\\n| `log_model` | Log all models if `log_model=\"all\"` or at end of training if `log_model=True` |\\n\\n| `save_dir`  | Path where data is saved                                                      |\\n\\n### Log your LightningModule hyperparameters\\n\\n```python\\n\\nclass LitModule(LightningModule):\\n\\ndef __init__(self, *args, **kwarg):\\n\\nself.save_hyperparameters()\\n\\n```\\n\\n### Log additional config parameters\\n\\n```python\\n\\n# add one parameter\\n\\nwandb_logger.experiment.config[\"key\"] = value\\n\\n# add multiple parameters\\n\\nwandb_logger.experiment.config.update({key1: val1, key2: val2})\\n\\n# use directly wandb module\\n\\nwandb.config[\"key\"] = value\\n\\nwandb.config.update()\\n\\n```\\n\\n### Log gradients, parameter histogram and model topology\\n\\nYou can pass your model object to `wandblogger.watch()` to monitor your models\\'s gradients and parameters as you train. See the PyTorch Lightning [**`WandbLogger` documentation**](https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch\\\\_lightning.loggers.WandbLogger.html?highlight=wandblogger) for a full description\\n\\n### Log metrics\\n\\nYou can log your metrics to W&B when using the `WandbLogger` by calling `self.log(\\'my_metric_name\\', metric_vale)` within your `LightningModule`, such as in your `training_step` or __ `validation_step methods.`\\n\\nThe code snippet below shows how to define your `LightningModule` to log your metrics and your `LightningModule` hyperparameters. In this example we will use the [`torchmetrics`](https://github.com/PyTorchLightning/metrics) library to calculate our metrics\\n\\n```python\\n\\nimport torch\\n\\nfrom torch.nn import Linear, CrossEntropyLoss, functional as F\\n\\nfrom torch.optim import Adam\\n\\nfrom torchmetrics.functional import accuracy\\n\\nfrom pytorch_lightning import LightningModule\\n\\nclass My_LitModule(LightningModule):\\n\\ndef __init__(self, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3):\\n\\n\\'\\'\\'method used to define our model parameters\\'\\'\\'\\n\\nsuper().__init__()\\n\\n# mnist images are (1, 28, 28) (channels, width, height)\\n\\nself.layer_1 = Linear(28 * 28, n_layer_1)\\n\\nself.layer_2 = Linear(n_layer_1, n_layer_2)\\n\\nself.layer_3 = Linear(n_layer_2, n_classes)\\n\\nself.loss = CrossEntropyLoss()\\n\\nself.lr = lr\\n\\n# save hyper-parameters to self.hparams (auto-logged by W&B)\\n\\nself.save_hyperparameters()\\n\\ndef forward(self, x):\\n\\n\\'\\'\\'method used for inference input -> output\\'\\'\\'\\n\\n# (b, 1, 28, 28) -> (b, 1*28*28)\\n\\nbatch_size, channels, width, height = x.size()\\n\\nx = x.view(batch_size, -1)\\n\\n# let\\'s do 3 x (linear + relu)\\n\\nx = F.relu(self.layer_1(x))\\n\\nx = F.relu(self.layer_2(x))\\n\\nx = self.layer_3(x)\\n\\nreturn x\\n\\ndef training_step(self, batch, batch_idx):\\n\\n\\'\\'\\'needs to return a loss from a single batch\\'\\'\\'\\n\\n_, loss, acc = self._get_preds_loss_accuracy(batch)\\n\\n# Log loss and metric\\n\\nself.log(\\'train_loss\\', loss)\\n\\nself.log(\\'train_accuracy\\', acc)\\n\\nreturn loss\\n\\ndef validation_step(self, batch, batch_idx):\\n\\n\\'\\'\\'used for logging metrics\\'\\'\\'\\n\\npreds, loss, acc = self._get_preds_loss_accuracy(batch)\\n\\n# Log loss and metric\\n\\nself.log(\\'val_loss\\', loss)\\n\\nself.log(\\'val_accuracy\\', acc)\\n\\nreturn preds\\n\\ndef configure_optimizers(self):\\n\\n\\'\\'\\'defines model optimizer\\'\\'\\'\\n\\nreturn Adam(self.parameters(), lr=self.lr)\\n\\ndef _get_preds_loss_accuracy(self, batch):\\n\\n\\'\\'\\'convenience function since train/valid/test steps are similar\\'\\'\\'\\n\\nx, y = batch\\n\\nlogits = self(x)\\n\\npreds = torch.argmax(logits, dim=1)\\n\\nloss = self.loss(logits, y)\\n\\nacc = accuracy(preds, y)\\n\\nreturn preds, loss, acc\\n\\n```\\n\\n### Log the min/max of your metric\\n\\nUsing wandb\\'s [`define_metric`](https://docs.wandb.ai/ref/python/run#define\\\\_metric) function you can define whether you\\'d like your W&B summary metric to display the min, max, mean or best value for that metric. If `define`_`metric` _ isn\\'t used, then the last value logged with appear in your summary metrics. See the `define_metric` [reference docs here](https://docs.wandb.ai/ref/python/run#define\\\\_metric) and the [guide here](https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define\\\\_metric) for more.\\n\\nTo tell W&B to keep track of the max validation accuracy in the W&B summary metric, you just need to call `wandb.define_metric` once, e.g. you can call it at the beginning of training like so:\\n\\n```python\\n\\nclass My_LitModule(LightningModule):\\n\\n...\\n\\ndef validation_step(self, batch, batch_idx):\\n\\nif trainer.global_step == 0:\\n\\nwandb.define_metric(\\'val_accuracy\\', summary=\\'max\\')\\n\\npreds, loss, acc = self._get_preds_loss_accuracy(batch)\\n\\n# Log loss and metric\\n\\nself.log(\\'val_loss\\', loss)\\n\\nself.log(\\'val_accuracy\\', acc)\\n\\nreturn preds\\n\\n```\\n\\n### Model Checkpointing\\n\\nCustom checkpointing to W&B can be set up through the PyTorch Lightning [`ModelCheckpoint`](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch\\\\_lightning.callbacks.ModelCheckpoint.html#pytorch\\\\_lightning.callbacks.ModelCheckpoint) when the log\\\\_model argument is used in the `WandbLogger`:\\n\\n```python\\n\\n# log model only if `val_accuracy` increases\\n\\nwandb_logger = WandbLogger(log_model=\"all\")\\n\\ncheckpoint_callback = ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\")\\n\\ntrainer = Trainer(logger=wandb_logger, callbacks=[checkpoint_callback])\\n\\n```\\n\\nThe _latest_ and _best_ aliases are automatically set to easily retrieve a model checkpoint from W&B Artifacts:\\n\\n```python\\n\\n# reference can be retrieved in artifacts panel\\n\\n# \"VERSION\" can be a version (ex: \"v2\") or an alias (\"latest or \"best\")\\n\\ncheckpoint_reference = \"USER/PROJECT/MODEL-RUN_ID:VERSION\"\\n\\n# download checkpoint locally (if not already cached)\\n\\nrun = wandb.init(project=\"MNIST\")\\n\\nartifact = run.use_artifact(checkpoint_reference, type=\"model\")\\n\\nartifact_dir = artifact.download()\\n\\n# load checkpoint\\n\\nmodel = LitModule.load_from_checkpoint(Path(artifact_dir) / \"model.ckpt\")\\n\\n```\\n\\n### Log images, text and more\\n\\nThe `WandbLogger` has `log_image`, `log_text` and `log_table` methods for logging media.\\n\\nYou can also directly call `wandb.log` or `trainer.logger.experiment.log` to log other media types such as Audio, Molecules, Point Clouds, 3D Objects and more.\\n\\n<Tabs\\n\\ndefaultValue=\"images\"\\n\\nvalues={[\\n\\n{label: \\'Log Images\\', value: \\'images\\'},\\n\\n{label: \\'Log Text\\', value: \\'text\\'},\\n\\n{label: \\'Log Tables\\', value: \\'tables\\'},\\n\\n]}>\\n\\n<TabItem value=\"images\">\\n\\n```python\\n\\n# using tensors, numpy arrays or PIL images\\n\\nwandb_logger.log_image(key=\"samples\", images=[img1, img2])\\n\\n# adding captions\\n\\nwandb_logger.log_image(key=\"samples\", images=[img1, img2], caption=[\"tree\", \"person\"])\\n\\n# using file path\\n\\nwandb_logger.log_image(key=\"samples\", images=[\"img_1.jpg\", \"img_2.jpg\"])\\n\\n# using .log in the trainer\\n\\ntrainer.logger.experiment.log({\\n\\n\"samples\": [wandb.Image(img, caption=caption)\\n\\nfor (img, caption) in my_images]\\n\\n})\\n\\n```\\n\\n</TabItem>\\n\\n<TabItem value=\"text\">\\n\\n```python\\n\\n# data should be a list of lists\\n\\ncolumns = [\"input\", \"label\", \"prediction\"]\\n\\nmy_data = [[\"cheese\", \"english\", \"english\"], [\"fromage\", \"french\", \"spanish\"]]\\n\\n# using columns and data\\n\\nwandb_logger.log_text(key=\"my_samples\", columns=columns, data=my_data)\\n\\n# using a pandas DataFrame\\n\\nwandb_logger.log_text(key=\"my_samples\", dataframe=my_dataframe)\\n\\n```\\n\\n</TabItem>\\n\\n<TabItem value=\"tables\">\\n\\n```python\\n\\n# log a W&B Table that has a text caption, an image and audio\\n\\ncolumns = [\"caption\", \"image\", \"sound\"]\\n\\n# data should be a list of lists\\n\\nmy_data = [[\"cheese\", wandb.Image(img_1), wandb.Audio(snd_1)],\\n\\n[\"wine\", wandb.Image(img_2), wandb.Audio(snd_2)]]\\n\\n# log the Table\\n\\nwandb_logger.log_table(key=\"my_samples\", columns=columns, data=data)\\n\\n```\\n\\n</TabItem>\\n\\n</Tabs>\\n\\nYou can use Lightning\\'s Callbacks system to control when you log to Weights & Biases via the WandbLogger, in this example we log a sample of our validation images and predictions:\\n\\n```python\\n\\nimport torch\\n\\nimport wandb\\n\\nimport pytorch_lightning as pl\\n\\nfrom pytorch_lightning.loggers import WandbLogger\\n\\nclass LogPredictionSamplesCallback(Callback):\\n\\ndef on_validation_batch_end(\\n\\nself, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\\n\\n\"\"\"Called when the validation batch ends.\"\"\"\\n\\n# `outputs` comes from `LightningModule.validation_step`\\n\\n# which corresponds to our model predictions in this case\\n\\n# Let\\'s log 20 sample image predictions from the first batch\\n\\nif batch_idx == 0:\\n\\nn = 20\\n\\nx, y = batch\\n\\nimages = [img for img in x[:n]]\\n\\ncaptions = [f\\'Ground Truth: {y_i} - Prediction: {y_pred}\\'\\n\\nfor y_i, y_pred in zip(y[:n], outputs[:n])]\\n\\n# Option 1: log images with `WandbLogger.log_image`\\n\\nwandb_logger.log_image(\\n\\nkey=\\'sample_images\\',\\n\\nimages=images,\\n\\ncaption=captions)\\n\\n# Option 2: log images and predictions as a W&B Table\\n\\ncolumns = [\\'image\\', \\'ground truth\\', \\'prediction\\']\\n\\ndata = [[wandb.Image(x_i), y_i, y_pred] f\\n\\nor x_i, y_i, y_pred in list(zip(x[:n], y[:n], outputs[:n]))]\\n\\nwandb_logger.log_table(\\n\\nkey=\\'sample_table\\',\\n\\ncolumns=columns,\\n\\ndata=data)\\n\\n...\\n\\ntrainer = pl.Trainer(\\n\\n...\\n\\ncallbacks=[LogPredictionSamplesCallback()]\\n\\n)\\n\\n```\\n\\n### How to use multiple GPUs with Lightning and W&B?\\n\\nPyTorch Lightning has Multi-GPU support through their DDP Interface. However, PyTorch Lightning\\'s design requires us to be careful about how we instantiate our GPUs.\\n\\nLightning assumes that each GPU (or Rank) in your training loop must be instantiated in exactly the same way - with the same initial conditions. However, only rank 0 process gets access to the `wandb.run` object, and for non-zero rank processes: `wandb.run = None`. This could cause your non-zero processes to fail. Such a situation can put you in a **deadlock** because rank 0 process will wait for the non-zero rank processes to join, which have already crashed.\\n\\nFor this reason, we have to be careful about how we set up our training code. The recommended way to set it up would be to have your code be independent of the `wandb.run` object.\\n\\n```python\\n\\nclass MNISTClassifier(pl.LightningModule):\\n\\ndef __init__(self):\\n\\nsuper(MNISTClassifier, self).__init__()\\n\\nself.model = nn.Sequential(\\n\\nnn.Flatten(),\\n\\nnn.Linear(28 * 28, 128),\\n\\nnn.ReLU(),\\n\\nnn.Linear(128, 10),\\n\\n)\\n\\nself.loss = nn.CrossEntropyLoss()\\n\\ndef forward(self, x):\\n\\nreturn self.model(x)\\n\\ndef training_step(self, batch, batch_idx):\\n\\nx, y = batch\\n\\ny_hat = self.forward(x)\\n\\nloss = self.loss(y_hat, y)\\n\\nself.log(\"train/loss\", loss)\\n\\nreturn {\"train_loss\": loss}\\n\\ndef validation_step(self, batch, batch_idx):\\n\\nx, y = batch\\n\\ny_hat = self.forward(x)\\n\\nloss = self.loss(y_hat, y)\\n\\nself.log(\"val/loss\", loss)\\n\\nreturn {\"val_loss\": loss}\\n\\ndef configure_optimizers(self):\\n\\nreturn torch.optim.Adam(self.parameters(), lr=0.001)\\n\\ndef main():\\n\\n# Setting all the random seeds to the same value.\\n\\n# This is important in a distributed training setting.\\n\\n# Each rank will get its own set of initial weights.\\n\\n# If they don\\'t match up, the gradients will not match either,\\n\\n# leading to training that may not converge.\\n\\npl.seed_everything(1)\\n\\ntrain_loader = DataLoader(train_dataset,  batch_size = 64,\\n\\nshuffle = True,\\n\\nnum_workers = 4)\\n\\nval_loader = DataLoader(val_dataset,\\n\\nbatch_size = 64,\\n\\nshuffle = False,\\n\\nnum_workers = 4)\\n\\nmodel = MNISTClassifier()\\n\\nwandb_logger = WandbLogger(project = \"<project_name>\")\\n\\ncallbacks = [\\n\\nModelCheckpoint(\\n\\ndirpath = \"checkpoints\",\\n\\nevery_n_train_steps=100,\\n\\n),\\n\\n]\\n\\ntrainer = pl.Trainer(\\n\\nmax_epochs = 3,\\n\\ngpus = 2,\\n\\nlogger = wandb_logger,\\n\\nstrategy=\"ddp\",\\n\\ncallbacks=callbacks\\n\\n)\\n\\ntrainer.fit(model, train_loader, val_loader)\\n\\n```\\n\\n## Check out interactive examples!\\n\\nYou can follow along in our video tutorial with our tutorial colab [here](https://wandb.me/lit-colab)\\n\\n<!-- {% embed url=\"https://www.youtube.com/watch?v=hUXQm46TAKc\" %} -->\\n\\n## Frequently Asked Questions\\n\\n### How does W&B integrate with Lightning?\\n\\nThe core integration is based on the [Lightning `loggers` API](https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html), which lets you write much of your logging code in a framework-agnostic way. `Logger`s are passed to the [Lightning `Trainer`](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html) and are triggered based on that API\\'s rich [hook-and-callback system](https://pytorch-lightning.readthedocs.io/en/stable/extensions/callbacks.html). This keeps your research code well-separated from engineering and logging code.\\n\\n### What does the integration log without any additional code?\\n\\nWe\\'ll save your model checkpoints to W&B, where you can view them or download them for use in future runs. We\\'ll also capture [system metrics](../app/features/system-metrics.md), like GPU usage and network I/O, environment information, like hardware and OS information, [code state](../app/features/panels/code.md) (including git commit and diff patch, notebook contents and session history), and anything printed to the standard out.\\n\\n### What if I really need to use `wandb.run` in my training setup?\\n\\nYou will have to essentially expand the scope of the variable you need to access yourself. In other words, making sure that the initial conditions are the same on all processes.\\n\\n```python\\n\\nif os.environ.get(\"LOCAL_RANK\", None) is None:\\n\\nos.environ[\"WANDB_DIR\"] = wandb.run.dir\\n\\n```\\n\\nThen, you can use `os.environ[\"WANDB_DIR\"]` to set up the model checkpoints directory. This way, `wandb.run.dir` can be used by any non-zero rank processes as well.'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\model-management-concepts.md'}, page_content=\"--\\ndescription: 'Model Management: Data Model & Terminology'\\n---\\n\\n# Model Management Concepts\"),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\quickstart.md'}, page_content='--\\ndescription: Sweeps quickstart shows how to define, initialize, and run a sweep. There are four main steps\\n---\\n\\n# Quickstart'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\tables-quickstart.md'}, page_content='description: Explore how to use W&B Tables with this 5 minute Quickstart.\\n\\nTables Quickstart\\n\\nThe following Quickstart demonstrates how to log data tables, visualize data, and query data.\\n\\nSelect the button below to try a PyTorch Quickstart example project on MNIST data.\\n\\n1. Log a table\\n\\nwandb.init(). \\n2. Create a\\n\\nwandb.Table() object instance. Pass the name of the columns in your table along with the data for the\\n\\nrun.log() as a key-value pair. Provide a name for your table for the key, and pass the object instance of\\n\\npython\\nrun = wandb.init(project=\"table-test\")\\nmy_table = wandb.Table(columns=[\"a\", \"b\"], data=[[\"a1\", \"b1\"], [\"a2\", \"b2\"]])\\nrun.log({\"Table Name\": my_table})\\n\\nYou can optionally pass in a Pandas DataFrame to wandb.Table() Class. For more information on supported data types, see the wandb.Table in the W&B API Reference Guide.\\n\\n2. Visualize tables in the workspace\\n\\nView the resulting table in your workspace. Navigate to the W&B App and select the name of your Run in your Project workspace. A new panel is added for each unique table key.\\n\\nIn this example, my_table, is logged under the key \"Table Name\".\\n\\n3. Compare across model versions\\n\\nLog sample tables from multiple W&B Runs and compare results in the project workspace. In this example workspace, we show how to combine rows from multiple different versions in the same table.\\n\\nUse the table filter, sort, and grouping features to explore and evaluate model results.'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\tags.md'}, page_content='import Tabs from \\'@theme/Tabs\\';\\nimport TabItem from \\'@theme/TabItem\\';\\n\\nTags\\n\\nTags can be used to label runs with particular features that might not be obvious from the logged metrics or Artifact data -- this run\\'s model is in_production, that run is preemptible, this run represents the baseline.\\n\\nHow to add tags\\n\\nYou can add tags to a run when it is created: wandb.init(tags=[\"tag1\", \"tag2\"]) .\\n\\nYou can also update the tags of a run during training (e.g. if a particular metrics crosses a pre-defined threshold):\\n\\n```python\\nrun = wandb.init(entity=\"entity\", project=\"capsules\", tags=[\"debug\"])\\n\\n...\\n\\nif current_loss < threshold:\\n    run.tags = run.tags + (\"release_candidate\",)\\n```\\n\\nThere are also several ways to add tags after runs have been logged to Weights & Biases.\\n\\nAfter a run is created, you can update tags using our public API like so:\\n\\npython\\nrun = wandb.Api().run(\"{entity}/{project}/{run-id}\"})\\nrun.tags.append(\"tag1\")  # you can choose tags based on run data here\\nrun.update()\\n\\nYou can read more about how to use the Public API in the reference documentation or guide.\\n\\nThis method is best suited to tagging large numbers of runs with the same tag or tags.\\n\\nIn the runs sidebar of the Project Page,  click the table icon in the upper-right.  This will expand the sidebar into the full runs table.\\n\\nHover over a run in the table to see a checkbox on the left or look in the header row for a checkbox that will allow you to select all runs.\\n\\nClick the checkbox to enable bulk actions. Select the runs to which you\\'d like to apply your tag(s).\\n\\nClick the Tag button above the rows of runs.\\n\\nType a tag you\\'d like to add and click \"Add\" below the text box to add a new tag.\\n\\nThis method is best suited to applying a tag or tags to a single run by hand.\\n\\nIn the left sidebar of the Run Page, click the top Overview tab.\\n\\nNext to \"Tags\" is a gray â\\x9e\\x95 button. Click on that plus to add a tag.\\n\\nType a tag you\\'d like to add and click \"Add\" below the text box to add a new tag.\\n\\nHow to remove tags\\n\\nTags can also be removed from runs via the UI.\\n\\nThis method is best suited to removing tags from a large numbers of runs.\\n\\nIn the runs sidebar of the Project Page,  click the table icon in the upper-right.  This will expand the sidebar into the full runs table.\\n\\nHover over a run in the table to see a checkbox on the left or look in the header row for a checkbox that will allow you to select all runs.\\n\\nClick either checkbox to enable bulk actions. Select the runs to from which you\\'d like to remove your tag(s).\\n\\nClick the Tag button above the rows of runs.\\n\\nClick the checkbox next to a tag to remove it from the run.\\n\\nIn the left sidebar of the Run Page, click the top Overview tab. The tags on the run are visible here.\\n\\nHover over a tag and click the \"x\" to remove it from the run.'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\teams.md'}, page_content='description: >-\\n  Collaborate with your colleagues, share results, and track all the experiments\\n  across your team\\n\\nTeams\\n\\nUse W&B Teams as a central workspace for your ML team to build better models faster.\\n\\nTrack all the experiments your team has tried so you never duplicate work.\\n\\nSave and reproduce previously trained models.\\n\\nShare progress and results with your boss and collaborators.\\n\\nCatch regressions and immediately get alerted when performance drops.\\n\\nBenchmark model performance and compare model versions.\\n\\nCreate a collaborative team\\n\\nSign up or log in to your free W&B account.\\n\\nClick Invite Team in the navigation bar.\\n\\nCreate your team and invite collaborators.\\n\\n:::info\\nNote: Only the admin of an organization can create a new team.\\n:::\\n\\nInvite team members\\n\\nInvite new members to your team. \\n1. Ensure the team member already has a W&B Account. \\n2. Navigate to https://wandb.ai/subscriptions. \\n3. Select Manage members.\\n4. A model will appear. Provide the username or email for the Email or Username field, select a team for them to join from the Team dropdown menu, and select a role type from the Organizational Role dropdown menu.\\n\\nSelect the Add button.\\n\\n:::info\\n* If you have an Enterprise account, please contact your Account Executive to invite new members to your team.\\n:::\\n\\nCreate a Team Profile\\n\\nYou can customize your team\\'s profile page to show an introduction and showcase reports and projects that are visible to the public or team members. Present reports, projects, and external links.\\n\\nHighlight your best research to visitors by showcasing your best public reports\\n\\nShowcase the most active projects to make it easier for teammates to find them\\n\\nFind collaborators by adding external links to your company or research lab\\'s website and any papers you\\'ve published\\n\\nRemove team members\\n\\nTeam admins can open the team settings page and click the delete button next to the departing member\\'s name. Any runs that they logged to the team will remain after a user is removed.\\n\\nTeam Roles and Permissions\\n\\nSelect one a team role when you invite colleagues to join a team. There are four team role options:\\n\\nAdmin: Team admins can add and remove other admins or team members. They have permissions to modify all projects and full deletion permissions. This includes, but is not limited to, deleting runs, projects, artifacts, and sweeps.\\n\\nMember: A regular member of the team. A team member is invited by email by the team admin. A team member cannot invite other members. Team members can only delete runs and sweep runs created by that member. Suppose you have two members A and B. Member B moves a Run from team B\\'s project to a different project owned by Member A. Member A can not delete the Run Member B moved to Member A\\'s project. Only the member that creates the Run, or the team admin, can delete the run.\\n\\nService: A service worker, an API key useful for using W&B with your run automation tools. If you use the API key from a service account for your team, make sure to set the environment variable WANDB_USERNAME to attribute runs to the correct user.\\n\\nView-Only (Enterprise-only feature): View-Only members can view assets within the team such as runs, reports, and workspaces. They can follow and comment on reports, but they can not create, edit, or delete project overview, reports, or runs. View-Only members do not have an API key.\\n\\nTeam Settings\\n\\nTeam settings allow you to manage the settings for your team and its members. With these privileges, you can effectively oversee and organize your team within Weights & Biases.\\n\\n| Permissions         | View-Only | Team Member | Team Admin | \\n| ------------------- | --------- | ----------- | ---------- |\\n| Add team members    |           |             |     X      |\\n| Remove team members |           |             |     X      |\\n| Manage team settings|           |             |     X      |\\n\\nModel Registry\\n\\nThe proceeding table lists permissions that apply to all projects across a given team.\\n\\n| Permissions                | View-Only | Team Member | Team Admin | \\n| ---------------------------| --------- | ----------- | ---------- |\\n| Add aliases                |           | X           | X          |\\n| Add models to the registry |           | X           | X          |\\n| View models in the registry| X         | X           | X          |\\n|Download models             | X         | X           | X          |\\n\\nReports\\n\\nReport permissions grant access to create, view, and edit reports. The proceeding table lists permissions that apply to all reports across a given team.\\n\\n| Permissions   | View-Only | Team Member                                     | Team Admin | \\n| -----------   | --------- | ----------------------------------------------- | ---------- |\\n|View reports   | X         | X                                               | X          |\\n|Create reports |           | X                                               | X          |\\n|Edit reports   |           | X (team members can only edit their own reports)| X          |\\n|Delete reports |           | X (team members can only edit their own reports)| X          |\\n\\nExperiments\\n\\nThe proceeding table lists permissions that apply to all experiments across a given team.\\n\\n| Permissions | View-Only | Team Member | Team Admin | \\n| ------------------------------------------------------------------------------------ | --------- | ----------- | ---------- |\\n| View experiment metadata (includes history metrics, system metrics, files, and logs) | X         | X           | X          |\\n| Log experiments                                                                      | X         | X           | X          |\\n| Delete experiments                                                                   |           | X (team members can only delete experiments they created) |  X  |\\n|Stop experiments                                                                      |           | X (team members can only stop experiments they created)   |  X  |\\n\\nArtifacts\\n\\nThe proceeding table lists permissions that apply to all artifacts across a given team.\\n\\n| Permissions      | View-Only | Team Member | Team Admin | \\n| ---------------- | --------- | ----------- | ---------- |\\n| View artifacts   | X         | X           | X          |\\n| Create artifacts |           | X           | X          |\\n| Delete artifacts |           | X           | X          |\\n| Edit metadata    |           | X           | X          |\\n| Edit aliases     |           | X           | X          |\\n| Delete aliases   |           | X           | X          |\\n| Download artifact|           | X           | X          |\\n\\nSystem Settings (W&B Server Only)\\n\\nWith system permissions, you have the ability to manage members, create and modify teams, adjust system settings, and view user activity. These privileges enable you to effectively administer and maintain the Weights & Biases instance.\\n\\n| Permissions              | View-Only | Team Member | Team Admin | System Admin | \\n| ------------------------ | --------- | ----------- | ---------- | ------------ |\\n| Configure system settings|           |             |            | X            |\\n| Create/delete teams      |           |             |            | X            |\\n| View activity dashboard  |           |             |            | X            |\\n\\nAdd Social Badges to your Intro\\n\\nIn your Intro, type / and choose Markdown and paste the markdown snippet that will render your badge. Once you convert it to WYSIWYG, you can resize it.\\n\\nFor example, to add a Twitter follow badge, add [![Twitter: @weights_biase](https://img.shields.io/twitter/follow/weights_biases?style=social)](https://twitter.com/intent/follow?screen_name=weights_biases replacing weights_biases with your Twitter username.\\n\\nTeam Trials\\n\\nW&B offers free trials for business teams, no credit card required. During the trial, you and your colleagues will have access to all the features in W&B. Once the trial is over, you can upgrade your plan to continue using a W&B Team to collaborate. Your personal W&B account will always remain free, and if you\\'re a student or teacher you can enroll in an academic plan.\\n\\nSee the pricing page for more information on our plans. You can download all your data at any time, either using the dashboard UI or via our Export API.\\n\\nChange the account settings for an organization\\n\\nIf you\\'re a paid user, then you can go to your \\'Subscriptions\\' page and click on the three dots next to the \\'Account\\' next to your organization name. You\\'ll be then able to edit the billing info for your organization, add seats to your org or contact sales to upgrade your plan.\\n\\nSimilarly, if your organization is still on trial then you can go to your \\'Subscriptions\\' page and click on the three dots next to the \\'Account\\' to update your account settings. Then, you\\'ll be able to add seats to your org, contact sales to upgrade your plan, etc.\\n\\nChange the billing user of an organization\\n\\nChange the billing user of your organization by clicking on the \"Manage members\" button on your subscription page.\\n\\nPrivacy settings\\n\\nYou can see the privacy settings of all team projects on the team settings page:\\napp.wandb.ai/teams/your-team-name'),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\track-external-files.md'}, page_content=\"--\\ndescription: Track files saved outside the Weights & Biases such as in an Amazon S3 bucket, GCS bucket, HTTP file server, or even an NFS share.\\n---\\n\\n# Track external files\\n\\nAWS_ACCESS_KEY_ID\\n\\nAWS_SECRET_ACCESS_KEY\\n\\nAWS_SESSION_TOKEN | `GOOGLE_APPLICATION_CREDENTIALS`                              |\\n| 2 - Shared credentials file | `~/.aws/credentials`                                                                                                | `application_default_credentials.json` in `~/.config/gcloud/` |\\n| 3 - Config file             | `~/.aws.config`                                                                                                     | N/A                                                           |\\n\\nInteract with this artifact similarly to a normal artifact. In the App UI, you can look through the contents of the reference artifact using the file browser, explore the full dependency graph, and scan through the versioned history of your artifact.\\n\\n:::caution\\nRich media such as images, audio, video, and point clouds may fail to render in the App UI depending on the CORS configuration of your bucket. Allow listing **app.wandb.ai** in your bucket's CORS settings will allow the App UI to properly render such rich media.\\n\\nPanels might fail to render in the App UI for private buckets. If your company has a VPN, you could update your bucket's access policy to whitelist IPs within your VPN.\\n:::\\n\\n### Download a reference artifact\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\nartifact = run.use_artifact('mnist:latest', type='dataset')\\nartifact_dir = artifact.download()\\n```\\n\\nWeights & Biases will use the metadata recorded when the artifact was logged to retrieve the files from the underlying bucket when it downloads a reference artifact. If your bucket has object versioning enabled, Weights & Biases will retrieve the object version corresponding to the state of the file at the time an artifact was logged. This means that as you evolve the contents of your bucket, you can still point to the exact iteration of your data a given model was trained on since the artifact serves as a snapshot of your bucket at the time of training.\\n\\n:::info\\nW&B recommends that you enable 'Object Versioning' on your Amazon S3 or GCS buckets if you overwrite files as part of your workflow. With versioning enabled on your buckets, artifacts with references to files that have been overwritten will still be intact because the older object versions are retained.\\n:::\\n\\n### Tying it together\\n\\nThe following code example demonstrates a simple workflow you can use to track a dataset in Amazon S3 or GCS that feeds into a training job:\\n\\n```python\\n import wandb\\n\\nrun = wandb.init()\\n\\nartifact = wandb.Artifact('mnist', type='dataset')\\nartifact.add_reference('s3://my-bucket/datasets/mnist')\\n\\n# Track the artifact and mark it as an input to\\n# this run in one swoop. A new artifact version\\n# is only logged if the files in the bucket changed.\\nrun.use_artifact(artifact)\\n\\nartifact_dir = artifact.download()\\n\\n# Perform training here...\\n```\\n\\nTo track models, we can log the model artifact after the training script uploads the model files to the bucket:\\n\\n```python\\nimport boto3\\nimport wandb\\n\\nrun = wandb.init()\\n\\n# Training here... \\n\\ns3_client = boto3.client('s3')\\ns3_client.upload_file('my_model.h5', 'my-bucket', 'models/cnn/my_model.h5')\\n\\nmodel_artifact = wandb.Artifact('cnn', type='model')\\nmodel_artifact.add_reference('s3://my-bucket/models/cnn/')\\nrun.log_artifact(model_artifact)\\n```\\n\\nFor an example of tracking reference files in GCP, with code and screenshots, follow our [Guide to Tracking Artifacts by Reference](https://wandb.ai/stacey/artifacts/reports/Tracking-Artifacts-by-Reference--Vmlldzo1NDMwOTE).\\n\\n### Filesystem References\\n\\nAnother common pattern for fast access to datasets is to expose an NFS mount point to a remote filesystem on all machines running training jobs. This can be an even simpler solution than a cloud storage bucket because from the perspective of the training script, the files look just like they are sitting on your local filesystem. Luckily, that ease of use extends into using Artifacts to track references to file systems – mounted or otherwise.\\n\\nAssume we have a filesystem mounted at `/mount` with the following structure:\\n\\n```\\nmount\\n+-- datasets/\\n|\\t\\t+-- mnist/\\n+-- models/\\n\\t\\t+-- cnn/\\n```\\n\\nUnder `mnist/` we have our dataset, a collection of images. Let's track it with an artifact:\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\nartifact = wandb.Artifact('mnist', type='dataset')\\nartifact.add_reference('file:///mount/datasets/mnist/')\\nrun.log_artifact(artifact)\\n```\\n\\nBy default, W&B imposes a 10,000 file limit when adding a reference to a directory. You can adjust this limit by specifying `max_objects=` in calls to `add_reference`.\\n\\nNote the triple slash in the URL. The first component is the `file://` prefix that denotes the use of filesystem references. The second is the path to our dataset, `/mount/datasets/mnist/`.\\n\\nThe resulting artifact `mnist:latest` looks and acts just like a regular artifact. The only difference is that the artifact only consists of metadata about the files, such as their sizes and MD5 checksums. The files themselves never leave your system.\\n\\nYou can interact with this artifact just as you would a normal artifact. In the UI, you can browse the contents of the reference artifact using the file browser, explore the full dependency graph, and scan through the versioned history of your artifact. However, the UI will not be able to render rich media such as images, audio, etc. as the data itself is not contained within the artifact.\\n\\nDownloading a reference artifact is simple:\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\nartifact = run.use_artifact('entity/project/mnist:latest', type='dataset')\\nartifact_dir = artifact.download()\\n```\\n\\nFor filesystem references, a `download()` operation copies the files from the referenced paths to construct the artifact directory. In the above example, the contents of `/mount/datasets/mnist` will be copied into the directory `artifacts/mnist:v0/`. If an artifact contains a reference to a file that was overwritten, then `download()` will throw an error as the artifact can no longer be reconstructed.\\n\\nPutting everything together, here's a simple workflow you can use to track a dataset under a mounted filesystem that feeds into a training job:\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\n\\nartifact = wandb.Artifact('mnist', type='dataset')\\nartifact.add_reference('file:///mount/datasets/mnist/')\\n\\n# Track the artifact and mark it as an input to\\n# this run in one swoop. A new artifact version\\n# is only logged if the files under the directory\\n# changed.\\nrun.use_artifact(artifact)\\n\\nartifact_dir = artifact.download()\\n\\n# Perform training here...\\n```\\n\\nTo track models, we can log the model artifact after the training script writes the model files to the mount point:\\n\\n```python\\nimport wandb\\n\\nrun = wandb.init()\\n\\n# Training here...\\n\\nwith open('/mount/cnn/my_model.h5') as f:\\n\\t# Output our model file.\\n\\nmodel_artifact = wandb.Artifact('cnn', type='model')\\nmodel_artifact.add_reference('file:///mount/cnn/my_model.h5')\\nrun.log_artifact(model_artifact)\\n```\"),\n",
              "  Document(metadata={'source': '..\\\\files\\\\docs_sample\\\\walkthrough.md'}, page_content='description: Tutorial of using the custom charts feature in the Weights & Biases UI\\n\\nCustom Charts Walkthrough\\n\\nTo go beyond the built-in charts in Weights & Biases, use the new Custom Charts feature to control the details of exactly what data you\\'re loading in to a panel and how you visualize that data.\\n\\nOverview\\n\\nLog data to W&B\\n\\nCreate a query\\n\\nCustomize the chart\\n\\n1. Log data to W&B\\n\\nFirst, log data in your script. Use wandb.config for single points set at the beginning of training, like hyperparameters. Use wandb.log() for multiple points over time, and log custom 2D arrays with wandb.Table(). We recommend logging up to 10,000 data points per logged key.\\n\\n```python\\n\\nLogging a custom table of data\\n\\nmy_custom_data = [[x1, y1, z1], [x2, y2, z2]]\\nwandb.log({\"custom_data_table\": wandb.Table(data=my_custom_data,\\n                                columns = [\"x\", \"y\", \"z\"])})\\n```\\n\\nTry a quick example notebook to log the data tables, and in the next step we\\'ll set up custom charts. See what the resulting charts look like in the live report.\\n\\n2. Create a query\\n\\nOnce you\\'ve logged data to visualize, go to your project page and click the + button to add a new panel, then select Custom Chart. You can follow along in this workspace.\\n\\nAdd a query\\n\\nClick summary and select historyTable to set up a new query pulling data from the run history.\\n\\nType in the key where you logged the wandb.Table(). In the code snippet above, it was my_custom_table . In the example notebook, the keys are pr_curve and roc_curve.\\n\\nSet Vega fields\\n\\nNow that the query is loading in these columns, they\\'re available as options to select in the Vega fields dropdown menus:\\n\\nx-axis: runSets_historyTable_r (recall)\\n\\ny-axis: runSets_historyTable_p (precision)\\n\\ncolor: runSets_historyTable_c (class label)\\n\\n3. Customize the chart\\n\\nNow that looks pretty good, but I\\'d like to switch from a scatter plot to a line plot. Click Edit to change the Vega spec for this built in chart. Follow along in this workspace.\\n\\nI updated the Vega spec to customize the visualization:\\n\\nadd titles for the plot, legend, x-axis, and y-axis (set \\x9ctitle\\x9d for each field)\\n\\nchange the value of \\x9cmark\\x9d from \\x9cpoint\\x9d to \\x9cline\\x9d\\n\\nremove the unused \\x9csize\\x9d field\\n\\nTo save this as a preset that you can use elsewhere in this project, click Save as at the top of the page. Here\\'s what the result looks like, along with an ROC curve:\\n\\nBonus: Composite Histograms\\n\\nHistograms can visualize numerical distributions to help us understand larger datasets. Composite histograms show multiple distributions across the same bins, letting us compare two or more metrics across different models or across different classes within our model. For a semantic segmentation model detecting objects in driving scenes, we might compare the effectiveness of optimizing for accuracy versus intersection over union (IOU), or we might want to know how well different models detect cars (large, common regions in the data) versus traffic signs (much smaller, less common regions). In the demo Colab, you can compare the confidence scores for two of the ten classes of living things.\\n\\nTo create your own version of the custom composite histogram panel:\\n\\nCreate a new Custom Chart panel in your Workspace or Report (by adding a \\x9cCustom Chart\\x9d visualization). Hit the \\x9cEdit\\x9d button in the top right to modify the Vega spec starting from any built-in panel type.\\n\\nReplace that built-in Vega spec with my MVP code for a composite histogram in Vega. You can modify the main title, axis titles, input domain, and any other details directly in this Vega spec using Vega syntax (you could change the colors or even add a third histogram :)\\n\\nModify the query in the right hand side to load the correct data from your wandb logs. Add the field \\x9csummaryTable\\x9d and set the corresponding \\x9ctableKey\\x9d to \\x9cclass_scores\\x9d to fetch the wandb.Table logged by your run. This will let you populate the two histogram bin sets (\\x9cred_bins\\x9d and \\x9cblue_bins\\x9d) via the dropdown menus with the columns of the wandb.Table logged as \\x9cclass_scores\\x9d. For my example, I chose the \\x9canimal\\x9d class prediction scores for the red bins and \\x9cplant\\x9d for the blue bins.\\n\\nYou can keep making changes to the Vega spec and query until you\\'re happy with the plot you see in the preview rendering. Once you\\'re done, click \\x9cSave as\\x9d in the top and give your custom plot a name so you can reuse it. Then click \\x9cApply from panel library\\x9d to finish your plot.\\n\\nHere\\'s what my results look like from a very brief experiment: training on only 1000 examples for one epoch yields a model that\\'s very confident that most images are not plants and very uncertain about which images might be animals.')])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "def find_md_files(directory):\n",
        "    'Find all markdown files in a directory and return a LangChain Document'\n",
        "    dl = DirectoryLoader(directory, '**/*.md')\n",
        "    return dl.load()\n",
        "\n",
        "documents = find_md_files('../files/docs_sample/')\n",
        "len(documents), documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wkrixoE-sYAN"
      },
      "outputs": [],
      "source": [
        "# We will need to count tokens in the documents, and for that we need the tokenizer\n",
        "tokenizer = tiktoken.encoding_for_model(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLjA4ndosYAN",
        "outputId": "f7519de9-8292-4441-a4fc-e8c1ef4677c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[26, 18, 2845, 4000, 18, 29, 335, 653, 1818, 1568, 1061]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def count_tokens(documents):\n",
        "    token_counts = [len(tokenizer.encode(document.page_content)) for document in documents]\n",
        "    return token_counts\n",
        "\n",
        "count_tokens(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVVcsjpAsYAN"
      },
      "source": [
        "We will use `LangChain` built in `MarkdownTextSplitter` to split the documents into sections. Actually splitting Markdown without breaking syntax is not that easy. This splitter strips out syntax.\n",
        "- We can pass the `chunk_size` param and avoid lenghty chunks.\n",
        "- The `chunk_overlap` param is useful so you don't cut sentences randomly. This is less necessary with Markdown\n",
        "\n",
        "The `MarkdownTextSplitter` also takes care of removing double line breaks and save us some tokens that way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icbIeb5hsYAN",
        "outputId": "c86e4b90-f4e8-4565-85ee-5c8da13060d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(81, 382)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import MarkdownTextSplitter\n",
        "\n",
        "md_text_splitter = MarkdownTextSplitter(chunk_size=1000)\n",
        "document_sections = md_text_splitter.split_documents(documents)\n",
        "len(document_sections), max(count_tokens(document_sections))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iojU9DcmsYAN"
      },
      "source": [
        "Let's look at the first section of our documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "dkPyM9VZsYAO",
        "outputId": "47e52060-ff3b-4026-8536-e0d6045c9993"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">wandb:                                                                                                             \n",
              "\n",
              "wandb: 🚀 View run comic-firebrand-342 at: https://wandb.ai/username/launch-quickstart/runs/p89pnj2u               \n",
              "\n",
              "wandb: Synced 5 W&amp;B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)                               \n",
              "\n",
              "wandb: Find logs at: ./wandb/run-20230323_120437-p89pnj2u/logs                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "wandb:                                                                                                             \n",
              "\n",
              "wandb: 🚀 View run comic-firebrand-342 at: https://wandb.ai/username/launch-quickstart/runs/p89pnj2u               \n",
              "\n",
              "wandb: Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 1 other file(s)                               \n",
              "\n",
              "wandb: Find logs at: ./wandb/run-20230323_120437-p89pnj2u/logs                                                     \n"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(document_sections[10].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAmxtl-qsYAO"
      },
      "source": [
        "## Embeddings\n",
        "Let's now use [LLM embeddings](https://irisagent.com/blog/understanding-llm-embeddings-a-comprehensive-guide/) with a [vector database retriever](https://www.analyticsvidhya.com/blog/2023/07/guide-to-chroma-db-a-vector-store-for-your-generative-ai-llms/) to find relevant documents for a query.\n",
        "If you are curious about using CHroma DB from langchain see this [link](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "69K60JuWsYAO"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# We will use the OpenAIEmbeddings to embed the text, and Chroma to store the vectors\n",
        "embeddings =  OpenAIEmbeddings()\n",
        "db = Chroma.from_documents(document_sections, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA2WBmDNsYAO"
      },
      "source": [
        "We can create a retriever from the db now, we can pass the k param to get the most relevant sections from the similarity search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8k9V01ysYAO"
      },
      "outputs": [],
      "source": [
        "# k is the number of sections to be retrieved that are the most relevant sections\n",
        "retriever = db.as_retriever(search_kargs=dict(k=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHZIeQJcv62y"
      },
      "outputs": [],
      "source": [
        "query = 'How can I share my W&B report with my team members in a public W&B project?'\n",
        "docs = retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UKj2q9AwtrO",
        "outputId": "91b93b80-8920-419d-ae74-afb9f200943e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "files/docs_sample/collaborate-on-reports.md\n",
            "files/docs_sample/teams.md\n",
            "files/docs_sample/teams.md\n",
            "files/docs_sample/teams.md\n"
          ]
        }
      ],
      "source": [
        "# Let's see the results\n",
        "for doc in docs:\n",
        "    print(doc.metadata['source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtAFgHBDz7kE",
        "outputId": "17082d12-8a0f-4569-d409-43ee3fd96386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--\n",
            "description: Collaborate and share W&B Reports with peers, co-workers, and your team.\n",
            "---\n",
            "\n",
            "# Collaborate on reports\n",
            "Team Trials\n",
            "\n",
            "W&B offers free trials for business teams, no credit card required. During the trial, you and your colleagues will have access to all the features in W&B. Once the trial is over, you can upgrade your plan to continue using a W&B Team to collaborate. Your personal W&B account will always remain free, and if you're a student or teacher you can enroll in an academic plan.\n",
            "\n",
            "See the pricing page for more information on our plans. You can download all your data at any time, either using the dashboard UI or via our Export API.\n",
            "\n",
            "Change the account settings for an organization\n",
            "\n",
            "If you're a paid user, then you can go to your 'Subscriptions' page and click on the three dots next to the 'Account' next to your organization name. You'll be then able to edit the billing info for your organization, add seats to your org or contact sales to upgrade your plan.\n",
            "description: >-\n",
            "  Collaborate with your colleagues, share results, and track all the experiments\n",
            "  across your team\n",
            "\n",
            "Teams\n",
            "\n",
            "Use W&B Teams as a central workspace for your ML team to build better models faster.\n",
            "\n",
            "Track all the experiments your team has tried so you never duplicate work.\n",
            "\n",
            "Save and reproduce previously trained models.\n",
            "\n",
            "Share progress and results with your boss and collaborators.\n",
            "\n",
            "Catch regressions and immediately get alerted when performance drops.\n",
            "\n",
            "Benchmark model performance and compare model versions.\n",
            "\n",
            "Create a collaborative team\n",
            "\n",
            "Sign up or log in to your free W&B account.\n",
            "\n",
            "Click Invite Team in the navigation bar.\n",
            "\n",
            "Create your team and invite collaborators.\n",
            "\n",
            ":::info\n",
            "Note: Only the admin of an organization can create a new team.\n",
            ":::\n",
            "\n",
            "Invite team members\n",
            "Click Invite Team in the navigation bar.\n",
            "\n",
            "Create your team and invite collaborators.\n",
            "\n",
            ":::info\n",
            "Note: Only the admin of an organization can create a new team.\n",
            ":::\n",
            "\n",
            "Invite team members\n",
            "\n",
            "Invite new members to your team. \n",
            "1. Ensure the team member already has a W&B Account. \n",
            "2. Navigate to https://wandb.ai/subscriptions. \n",
            "3. Select Manage members.\n",
            "4. A model will appear. Provide the username or email for the Email or Username field, select a team for them to join from the Team dropdown menu, and select a role type from the Organizational Role dropdown menu.\n",
            "\n",
            "Select the Add button.\n",
            "\n",
            ":::info\n",
            "* If you have an Enterprise account, please contact your Account Executive to invite new members to your team.\n",
            ":::\n",
            "\n",
            "Create a Team Profile\n",
            "\n",
            "You can customize your team's profile page to show an introduction and showcase reports and projects that are visible to the public or team members. Present reports, projects, and external links.\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIxJhLxfw94E"
      },
      "source": [
        "## Stuff Prompt\n",
        "We'll take the content of the retrieved documents, stuff them into prompt template along with the query, and pass into an LLM to obtain the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j8ZhixIwj4c"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"Use the following of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=['context', 'question']\n",
        ")\n",
        "context = '\\n\\n'.join(doc.page_content for doc in docs)\n",
        "prompt = PROMPT.format(context=context, question=query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvV4CIWEypY2"
      },
      "source": [
        "Use langchain to call openai chat API with the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "id": "CceauBXjxVDU",
        "outputId": "ae9fd56f-41e5-484d-d8e4-4ce8ae2a31fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share your W&amp;B report with your team members in a public W&amp;B project, you can invite them to your team and then \n",
              "add them as collaborators on the project. Additionally, you can customize your team's profile page to showcase the \n",
              "report and make it visible to the public or team members.                                                          \n",
              "</pre>\n"
            ],
            "text/plain": [
              "To share your W&B report with your team members in a public W&B project, you can invite them to your team and then \n",
              "add them as collaborators on the project. Additionally, you can customize your team's profile page to showcase the \n",
              "report and make it visible to the public or team members.                                                          \n"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import OpenAI\n",
        "llm = OpenAI()\n",
        "response = llm.invoke(prompt)\n",
        "Markdown(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idp-IcW_1Cqo"
      },
      "source": [
        "## Using Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QniCGQPe1HJr"
      },
      "source": [
        "Langchain gives us tools to do this efficiently in few lines of code. Lets do the same using `RetrievalQA` chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "b62Xa2Ujy09y",
        "outputId": "3121e695-89e9-464d-a0c3-c195e0cbff6c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share your W&amp;B report with your team members in a public W&amp;B project, you can create a team profile by          \n",
              "customizing your team's profile page. This will allow you to showcase reports and projects that are visible to the \n",
              "public or team members. You can also share external links on your team profile. Additionally, you can invite team  \n",
              "members to join your team and give them access to view and collaborate on your reports.                            \n",
              "</pre>\n"
            ],
            "text/plain": [
              "To share your W&B report with your team members in a public W&B project, you can create a team profile by          \n",
              "customizing your team's profile page. This will allow you to showcase reports and projects that are visible to the \n",
              "public or team members. You can also share external links on your team profile. Additionally, you can invite team  \n",
              "members to join your team and give them access to view and collaborate on your reports.                            \n"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type='stuff', retriever=retriever)\n",
        "result = qa.invoke(query)\n",
        "Markdown(result['result'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "76d92268d94048b4bdd5d1143821f57e",
            "6c05148006b944099a6236e13e4257b7",
            "31a73e0198d140ff9f2a379a063ba043",
            "40ae2f86e6ba435d9b6404b7a30ac649",
            "8daef492a3934ebcbe95136c0f72934c",
            "6591de0da01c4b18b3d8c5354dba191a",
            "663331291eee42bfbf3496926639f46c",
            "8520475a74da4a6497e91ecea735e869"
          ]
        },
        "id": "D9TaH2571mMZ",
        "outputId": "44d5d96b-1f30-4850-8f6e-513f6b6e4a46"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76d92268d94048b4bdd5d1143821f57e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.015 MB of 0.015 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">curious-snowflake-20</strong> at: <a href='https://wandb.ai/mary1378/llmapp/runs/ztgn5i8i' target=\"_blank\">https://wandb.ai/mary1378/llmapp/runs/ztgn5i8i</a><br/> View project at: <a href='https://wandb.ai/mary1378/llmapp' target=\"_blank\">https://wandb.ai/mary1378/llmapp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240802_065815-ztgn5i8i/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EEvFomU1xgd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31a73e0198d140ff9f2a379a063ba043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_663331291eee42bfbf3496926639f46c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8520475a74da4a6497e91ecea735e869",
            "value": 1
          }
        },
        "40ae2f86e6ba435d9b6404b7a30ac649": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6591de0da01c4b18b3d8c5354dba191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "663331291eee42bfbf3496926639f46c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c05148006b944099a6236e13e4257b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8daef492a3934ebcbe95136c0f72934c",
            "placeholder": "​",
            "style": "IPY_MODEL_6591de0da01c4b18b3d8c5354dba191a",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "76d92268d94048b4bdd5d1143821f57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c05148006b944099a6236e13e4257b7",
              "IPY_MODEL_31a73e0198d140ff9f2a379a063ba043"
            ],
            "layout": "IPY_MODEL_40ae2f86e6ba435d9b6404b7a30ac649"
          }
        },
        "8520475a74da4a6497e91ecea735e869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8daef492a3934ebcbe95136c0f72934c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

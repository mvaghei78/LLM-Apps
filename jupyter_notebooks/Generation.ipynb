{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "\n",
    "In this notebook we will dive deeper on prompting the model by passing a better context by using available data from users questions and using the documentation files to generate better answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqq rich openai tiktoken wandb tenacity pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, wget, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import openai\n",
    "import tiktoken\n",
    "from pprint import pprint\n",
    "from rich.markdown import Markdown\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential\n",
    ")\n",
    "import wandb\n",
    "from wandb.integration.openai import autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading OPENAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv('OPENAI_API_KEY') is None:\n",
    "    if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "        print('Plase enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "    os.environ['OPENAI_API_KEY'] == getpass('Paste your OpenAI key from: https://paltform.openai.com/account/api-key\\n')\n",
    "\n",
    "assert os.getenv('OPENAI_API_KEY',''.startswith('sk-')), \"This doesn't look like a valid OpenAI API key\"\n",
    "print('OpenAI API key configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable W&B to track our experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:r9re4caq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-moon-43</strong> at: <a href='https://wandb.ai/mary1378/llmapps/runs/r9re4caq' target=\"_blank\">https://wandb.ai/mary1378/llmapps/runs/r9re4caq</a><br/> View project at: <a href='https://wandb.ai/mary1378/llmapps' target=\"_blank\">https://wandb.ai/mary1378/llmapps</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240808_104646-r9re4caq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:r9re4caq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\MagicalAPI\\Jupyter notebooks - Introduction with LLM\\wandb\\run-20240808_104653-v8xppo89</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mary1378/llmapps/runs/v8xppo89' target=\"_blank\">elated-violet-44</a></strong> to <a href='https://wandb.ai/mary1378/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mary1378/llmapps' target=\"_blank\">https://wandb.ai/mary1378/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mary1378/llmapps/runs/v8xppo89' target=\"_blank\">https://wandb.ai/mary1378/llmapps/runs/v8xppo89</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mary1378/llmapps/runs/v8xppo89?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1d6c6fed710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start logging to W&B\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'generation.ipynb'\n",
    "# autolog(init={'project':'llmapps', 'job_type': 'generation'})\n",
    "wandb.init(project='llmapps', job_type='generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stat\n",
    "class Utils:\n",
    "    # Function to clone the repository\n",
    "    def clone_repo(self, repo_url, target_dir):\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.system(f'git config --global http.postBuffer 1048576000')\n",
    "            os.system(f'git clone --depth=1 {repo_url} {target_dir}')\n",
    "        else:\n",
    "            print(f\"Directory {target_dir} already exists.\")\n",
    "\n",
    "    # Function to get file absolute path\n",
    "    def get_file_name(self, dir):\n",
    "        file_list = []\n",
    "        for file in os.listdir(dir):\n",
    "            if os.path.isfile(os.path.join(dir, file)):\n",
    "                file_list.append(file)\n",
    "        return file_list\n",
    "    \n",
    "    # Function to copy files from one directory to another\n",
    "    def copy_dir(self, src_dir, dst_dir):\n",
    "        file_list = self.get_file_name(src_dir)\n",
    "        if not os.path.isdir(dst_dir):\n",
    "            os.makedirs(dst_dir)\n",
    "        if len(file_list) != 0:\n",
    "            for file_name in file_list:\n",
    "                src = os.path.join(src_dir, file_name)\n",
    "                dst = os.path.join(dst_dir, file_name)\n",
    "                print(f\"Copying {src} to {dst}\")\n",
    "                self.move_or_copy_file(src, dst, False)\n",
    "                \n",
    "    # Function to move one file from one directory to another\n",
    "    def move_or_copy_file(self, src_file, dst_file, move_file=True):\n",
    "        try:\n",
    "            if move_file:\n",
    "                shutil.move(src_file, dst_file)\n",
    "                print(f\"{src_file} moved successfully.\")\n",
    "            else:\n",
    "                shutil.copy(src_file, dst_file)\n",
    "                print(f\"{src_file} copied successfully.\")\n",
    "        # If source and destination are same\n",
    "        except shutil.SameFileError:\n",
    "            print(\"Source and destination represent the same file.\")\n",
    "        # If there is any permission issue\n",
    "        except PermissionError:\n",
    "            print(\"Permission denied.\")\n",
    "        # For other errors\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while copying file: {e}\")\n",
    "\n",
    "    # Function to handle read-only files\n",
    "    def handle_remove_readonly(self, func, path, exc_info):\n",
    "        os.chmod(path, stat.S_IWRITE)\n",
    "        func(path)\n",
    "\n",
    "    # Function to remove a directory with its files and folders inside it\n",
    "    def remove_dir(self, dir_path):\n",
    "        try:\n",
    "            if os.path.exists(dir_path):\n",
    "                shutil.rmtree(dir_path, onerror=self.handle_remove_readonly)\n",
    "                print(f\"Directory {dir_path} and all its contents have been removed successfully.\")\n",
    "            else:\n",
    "                print(f\"Directory {dir_path} does not exist.\")\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied while trying to remove {dir_path}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while removing directory {dir_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files on colab\n",
    "if not Path(\"../files/examples.txt\").exists():\n",
    "    for file_name in ['examples.txt','prompt_template.txt','system_template.txt']:\n",
    "        downloaded_file = wget.download(f'https://raw.githubusercontent.com/wandb/edu/main/llm-apps-course/notebooks/{file_name}')\n",
    "        Utils().move_or_copy_file(f'{file_name}', f'../files/{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../edu does not exist.\n"
     ]
    }
   ],
   "source": [
    "Utils().clone_repo('https://github.com/wandb/edu.git', '../edu')\n",
    "Utils().copy_dir(src_dir='../edu/llm-apps-course/docs_sample', dst_dir='../files/docs_sample')\n",
    "Utils().remove_dir('../edu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating synthetic support questions\n",
    "We will add a retry behavior in case we hit the [API rate limit](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.chat.completions.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting\n",
    "![prompting levels](../images/prompting.png \"Prompting Levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero-shot prompting \n",
    "In this type of prompting we are not giving the model any examples. we are not giving it any context, we're just asking it to do some work (here generating a support question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"Can you provide guidance on how to properly record the weight of an item when using the W&amp;B system?\"              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"Can you provide guidance on how to properly record the weight of an item when using the W&B system?\"              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"What's the best way to log a new workout in my W&amp;B app?\"                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"What's the best way to log a new workout in my W&B app?\"                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure, I can provide a sample support question related to W&amp;B:                                                      \n",
       "\n",
       "User Question: \"I'm having trouble tracking and visualizing my model's performance metrics with Weights &amp; Biases.  \n",
       "Can you guide me on how to set up and monitor these metrics effectively?\"                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sure, I can provide a sample support question related to W&B:                                                      \n",
       "\n",
       "User Question: \"I'm having trouble tracking and visualizing my model's performance metrics with Weights & Biases.  \n",
       "Can you guide me on how to set up and monitor these metrics effectively?\"                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"I am not able to see the weight and balance section in the app. How can I access it?\"                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"I am not able to see the weight and balance section in the app. How can I access it?\"                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"Can you provide guidance on how to properly track and manage my inventory levels within the W&amp;B software?\"        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"Can you provide guidance on how to properly track and manage my inventory levels within the W&B software?\"        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = 'You are a helpful assistant.'\n",
    "user_prompt = 'Generate  a support question from a W&B user'\n",
    "\n",
    "def generate_and_print(system_prompt, user_prompt, n=5):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    "    response = completion_with_backoff(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        n=n\n",
    "    )\n",
    "    for response in response.choices:\n",
    "        generation = response.message.content\n",
    "        display(Markdown(generation))\n",
    "\n",
    "generate_and_print(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot\n",
    "Let's read some user submitted queries from the file example.txt\n",
    "This file contains multiline questions seperated by tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'We have 228 real queries:'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sample one: 'how can i do .tight_layout() on my seaborn heatmap'                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sample one: 'how can i do .tight_layout() on my seaborn heatmap'                                                   \n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiter = '\\t' # tab seperated queries\n",
    "with open('../files/examples.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "    real_queries = data.split(delimiter)\n",
    "\n",
    "pprint(f'We have {len(real_queries)} real queries:')\n",
    "Markdown(f'Sample one: \\n\\'{random.choice(real_queries)}\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use those real user questions to guide our model to produce synthetic questions like those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a support question from a W&B user\n",
      " Below you will find a few examples of real user queries:\n",
      "I am logging the score of my LightGBM regression model by doing `run = wandb.init(project=project_name)` and then `wandb.log({'dev_score': dev_score})`. The problem is that it is logged as a chart with step-score x-y axes, and I only want the scalar value. As I do not have steps, it is difficult to visualize the score. How can I add a Scalar chart instead?\n",
      "how do i load the latest model from a specific project to continue training? Im using Pytorch.\n",
      "how can i get all the versions of an aritfact of a particular type?\n",
      "Let's start!\n"
     ]
    }
   ],
   "source": [
    "def generate_few_shot_prompt(queries, n=3):\n",
    "    prompt = 'Generate a support question from a W&B user\\n Below you will find a few examples of real user queries:\\n'\n",
    "    for i in range(n):\n",
    "        prompt += random.choice(queries) + '\\n'\n",
    "    prompt += \"Let's start!\"\n",
    "    return prompt\n",
    "\n",
    "generation_prompt = generate_few_shot_prompt(real_queries)\n",
    "print(generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I ensure that my updated LightGBM regression model is tracked with a Scalar chart in WandB, instead of a   \n",
       "chart with step-score x-y axes, to easily visualize the score without steps for better analysis?                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How can I ensure that my updated LightGBM regression model is tracked with a Scalar chart in WandB, instead of a   \n",
       "chart with step-score x-y axes, to easily visualize the score without steps for better analysis?                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I add a Scalar chart instead of a step-score chart when logging the score of my model using W&amp;B?           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How can I add a Scalar chart instead of a step-score chart when logging the score of my model using W&B?           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I stop the automatic syncing of large files to W&amp;B while still being able to log other metrics and         \n",
       "artifacts?                                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How can I stop the automatic syncing of large files to W&B while still being able to log other metrics and         \n",
       "artifacts?                                                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I add a Scalar chart for my metric logging in W&amp;B instead of the default chart with step-score x-y axes?   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How can I add a Scalar chart for my metric logging in W&B instead of the default chart with step-score x-y axes?   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I change the chart type from step x-y axes to a Scalar chart for a specific value logged in W&amp;B without    \n",
       "steps included?                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How can I change the chart type from step x-y axes to a Scalar chart for a specific value logged in W&B without    \n",
       "steps included?                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_print(system_prompt=system_prompt, user_prompt=generation_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Context & Response\n",
    "Let's create a function to find all the markdown files in a directory and return it's content and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_md_files(directory):\n",
    "    'Find all markdown files in a directory and return their content and path'\n",
    "    md_files = []\n",
    "    for file  in Path(directory).rglob('*.md'):\n",
    "        with open(file, 'r', encoding='utf-8') as md_file:\n",
    "            content = md_file.read()\n",
    "        md_files.append((file.relative_to(directory), content))\n",
    "    return md_files\n",
    "\n",
    "documents = find_md_files('../files/docs_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the documents are not too long for our context window. We need to compute the number of tokens in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[365, 2596, 2940, 4179, 803, 1206, 537, 956, 2093, 2529, 1644]\n"
     ]
    }
   ],
   "source": [
    "# Check how longs our documents are\n",
    "tokenizer = tiktoken.encoding_for_model(MODEL)\n",
    "tokens_per_document = [len(tokenizer.encode(document)) for _, document in documents]\n",
    "pprint(tokens_per_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them are too long - instead of using entire documents, we'll extract a random chunck from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a random chunck from a document\n",
    "def extract_random_chunk(document, max_tokens=512):\n",
    "    tokens = tokenizer.encode(document)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return document\n",
    "    start = random.randint(0, len(tokens) - max_tokens)\n",
    "    end = start + max_tokens\n",
    "    return tokenizer.decode(tokens[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use that extracted chunck to create a question that can be answered by the document. This way we can generate questions that our current documentation is capable of answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_prompt(chunk):\n",
    "    prompt = 'Generate a support question from a W&B user\\n The question should be answerable by provided fragment of W&B documentation.\\n Below you will find a fragment of W&B documentation:\\n'+\\\n",
    "    chunk + \"\\nLet's start!\"\n",
    "    return prompt\n",
    "\n",
    "chunk = extract_random_chunk(documents[0][1])\n",
    "generation_prompt = generate_context_prompt(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "     <span style=\"font-weight: bold; text-decoration: underline\">Generate a support question from a W&amp;B user The question should be answerable by provided fragment of W&amp;B</span>     \n",
       "                        <span style=\"font-weight: bold; text-decoration: underline\">documentation. Below you will find a fragment of W&amp;B documentation:</span>                        \n",
       "\n",
       "\n",
       "               <span style=\"font-weight: bold; text-decoration: underline\">description: Collaborate and share W&amp;B Reports with peers, co-workers, and your team.</span>               \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                             <span style=\"font-weight: bold\">Collaborate on reports</span>                                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "Once you have saved a report, you can select the <span style=\"font-weight: bold\">Share</span> button to collaborate. A draft copy of the report is created\n",
       "when you select the <span style=\"font-weight: bold\">Edit</span> button. Draft reports auto-save. Select <span style=\"font-weight: bold\">Save to report</span> to publish your changes to the     \n",
       "shared report.                                                                                                     \n",
       "\n",
       "A warning notification will appear if an edit conflict occurs. This can occur if you and another collaborator edit \n",
       "the same report at the same time. The warning notification will guide you to resolve potential edit conflicts.     \n",
       "\n",
       "🌆 <a href=\"@site/static/images/reports/share-report.gif\" target=\"_blank\">Report sharing modal for a report in a 'Public' project</a>                                                                                                                    \n",
       "\n",
       "                                                <span style=\"font-weight: bold\">Comment on reports</span>                                                 \n",
       "\n",
       "Click the comment button on a panel in a report to add a comment directly to that panel.                           \n",
       "\n",
       "🌆 <a href=\"/images/reports/demo_comment_on_panels_in_reports.gif\" target=\"_blank\">Adding a comment to a panel</a>                                                                                                                    \n",
       "\n",
       "                                          <span style=\"font-weight: bold\">Who can edit and share reports?</span>                                          \n",
       "\n",
       "Reports that are created within an individual's private project is only visible to that user. The user can share   \n",
       "their project to a team or to the public.                                                                          \n",
       "\n",
       "On team projects, both the administrator, or member who created the report, can toggle permissions between edit or \n",
       "view access for other team members. Team members can share reports.                                                \n",
       "\n",
       "To share a report, select the <span style=\"font-weight: bold\">Share</span> button on the upper right hand corner.  You can either provide an email account\n",
       "or copy the magic link. Users invited by email will need to log into Weights &amp; Biases to view the report. Users who\n",
       "are given a magic link to not need to log into Weights &amp; Biases to view the report.                                \n",
       "\n",
       "Shared reports are view-only.                                                                                      \n",
       "\n",
       "Let's start!                                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "     \u001b[1;4mGenerate a support question from a W&B user\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4mThe question should be answerable by provided fragment of W&B\u001b[0m     \n",
       "                        \u001b[1;4mdocumentation.\u001b[0m\u001b[1;4m \u001b[0m\u001b[1;4mBelow you will find a fragment of W&B documentation:\u001b[0m                        \n",
       "\n",
       "\n",
       "               \u001b[1;4mdescription: Collaborate and share W&B Reports with peers, co-workers, and your team.\u001b[0m               \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                             \u001b[1mCollaborate on reports\u001b[0m                                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "Once you have saved a report, you can select the \u001b[1mShare\u001b[0m button to collaborate. A draft copy of the report is created\n",
       "when you select the \u001b[1mEdit\u001b[0m button. Draft reports auto-save. Select \u001b[1mSave to report\u001b[0m to publish your changes to the     \n",
       "shared report.                                                                                                     \n",
       "\n",
       "A warning notification will appear if an edit conflict occurs. This can occur if you and another collaborator edit \n",
       "the same report at the same time. The warning notification will guide you to resolve potential edit conflicts.     \n",
       "\n",
       "🌆 \u001b]8;id=627207;@site/static/images/reports/share-report.gif\u001b\\Report sharing modal for a report in a 'Public' project\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "                                                \u001b[1mComment on reports\u001b[0m                                                 \n",
       "\n",
       "Click the comment button on a panel in a report to add a comment directly to that panel.                           \n",
       "\n",
       "🌆 \u001b]8;id=151551;/images/reports/demo_comment_on_panels_in_reports.gif\u001b\\Adding a comment to a panel\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "                                          \u001b[1mWho can edit and share reports?\u001b[0m                                          \n",
       "\n",
       "Reports that are created within an individual's private project is only visible to that user. The user can share   \n",
       "their project to a team or to the public.                                                                          \n",
       "\n",
       "On team projects, both the administrator, or member who created the report, can toggle permissions between edit or \n",
       "view access for other team members. Team members can share reports.                                                \n",
       "\n",
       "To share a report, select the \u001b[1mShare\u001b[0m button on the upper right hand corner.  You can either provide an email account\n",
       "or copy the magic link. Users invited by email will need to log into Weights & Biases to view the report. Users who\n",
       "are given a magic link to not need to log into Weights & Biases to view the report.                                \n",
       "\n",
       "Shared reports are view-only.                                                                                      \n",
       "\n",
       "Let's start!                                                                                                       \n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Support Question Generated: How can I share a W&amp;B report with other team members or collaborators outside my       \n",
       "organization?                                                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Support Question Generated: How can I share a W&B report with other team members or collaborators outside my       \n",
       "organization?                                                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Support Question: How can I share a report with other team members or external collaborators in my project on W&amp;B? \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Support Question: How can I share a report with other team members or external collaborators in my project on W&B? \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Support Question from a W&amp;B User: \"How can I resolve an edit conflict when collaborating on W&amp;B Reports with my    \n",
       "team?\"                                                                                                             \n",
       "\n",
       "Answerable by provided fragment of W&amp;B documentation: \"A warning notification will appear if an edit conflict      \n",
       "occurs when collaborating on a report. The warning notification will guide you to resolve potential edit           \n",
       "conflicts.\"                                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Support Question from a W&B User: \"How can I resolve an edit conflict when collaborating on W&B Reports with my    \n",
       "team?\"                                                                                                             \n",
       "\n",
       "Answerable by provided fragment of W&B documentation: \"A warning notification will appear if an edit conflict      \n",
       "occurs when collaborating on a report. The warning notification will guide you to resolve potential edit           \n",
       "conflicts.\"                                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_print(system_prompt, generation_prompt, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 5 prompting\n",
    "complex directive that include the following:\n",
    "- Description of high-level goal\n",
    "- A detailed bulleted list of sub-tasks\n",
    "- An explicit statement asking LLM to explain its own output\n",
    "- A guideline on how LLM output will be evaluated\n",
    "- Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../files/system_template.txt', 'r') as file:\n",
    "    system_prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are a creative assistant with the goal to generate a synthetic dataset of Weights &amp; Biases (W&amp;B) user          \n",
       "questions. W&amp;B users are asking these questions to a bot, so they don't know the answer and their questions are    \n",
       "grounded in what they're trying to achieve. We are interested in questions that can be answered by W&amp;B             \n",
       "documentation. But the users don't have access to this documentation, so you need to imagine what they're trying to\n",
       "do and use according language.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are a creative assistant with the goal to generate a synthetic dataset of Weights & Biases (W&B) user          \n",
       "questions. W&B users are asking these questions to a bot, so they don't know the answer and their questions are    \n",
       "grounded in what they're trying to achieve. We are interested in questions that can be answered by W&B             \n",
       "documentation. But the users don't have access to this documentation, so you need to imagine what they're trying to\n",
       "do and use according language.                                                                                     \n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../files/prompt_template.txt', 'r') as file:\n",
    "    prompt_template = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mMarkdown\u001b[49m(prompt_template)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Markdown' is not defined"
     ]
    }
   ],
   "source": [
    "Markdown(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_prompt(chunk, n_questions=3):\n",
    "    questions = '\\n'.join(random.sample(real_queries, n_questions))\n",
    "    user_prompt = prompt_template.format(QUESTIONS=questions, CHUNK=chunk)\n",
    "    return user_prompt\n",
    "\n",
    "user_prompt = generate_context_prompt(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "how do I use the n Weights &amp; Biases LangChain integration? How can I log and visualize time series data in WandB? I\n",
       "am logging the score of my LightGBM regression model by doing <span style=\"color: #008080; text-decoration-color: #008080; background-color: #000000; font-weight: bold\">wandb.log({'dev_score': dev_score})</span>. The problem is  \n",
       "that it is logged as a chart with step-score x-y axes, and I only want the scalar value. As I do not have steps, it\n",
       "is difficult to visualize the score. How can I add a Scalar chart instead?                                         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "In the next step, you will read a fragment of W&amp;B documentation. This will serve as inspiration for synthetic user \n",
       "question and the source of the answer. Here is the document fragment:                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "\n",
       "               <span style=\"font-weight: bold; text-decoration: underline\">description: Collaborate and share W&amp;B Reports with peers, co-workers, and your team.</span>               \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                             <span style=\"font-weight: bold\">Collaborate on reports</span>                                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "Once you have saved a report, you can select the <span style=\"font-weight: bold\">Share</span> button to collaborate. A draft copy of the report is created\n",
       "when you select the <span style=\"font-weight: bold\">Edit</span> button. Draft reports auto-save. Select <span style=\"font-weight: bold\">Save to report</span> to publish your changes to the     \n",
       "shared report.                                                                                                     \n",
       "\n",
       "A warning notification will appear if an edit conflict occurs. This can occur if you and another collaborator edit \n",
       "the same report at the same time. The warning notification will guide you to resolve potential edit conflicts.     \n",
       "\n",
       "🌆 <a href=\"@site/static/images/reports/share-report.gif\" target=\"_blank\">Report sharing modal for a report in a 'Public' project</a>                                                                                                                    \n",
       "\n",
       "                                                <span style=\"font-weight: bold\">Comment on reports</span>                                                 \n",
       "\n",
       "Click the comment button on a panel in a report to add a comment directly to that panel.                           \n",
       "\n",
       "🌆 <a href=\"/images/reports/demo_comment_on_panels_in_reports.gif\" target=\"_blank\">Adding a comment to a panel</a>                                                                                                                    \n",
       "\n",
       "                                          <span style=\"font-weight: bold\">Who can edit and share reports?</span>                                          \n",
       "\n",
       "Reports that are created within an individual's private project is only visible to that user. The user can share   \n",
       "their project to a team or to the public.                                                                          \n",
       "\n",
       "On team projects, both the administrator, or member who created the report, can toggle permissions between edit or \n",
       "view access for other team members. Team members can share reports.                                                \n",
       "\n",
       "To share a report, select the <span style=\"font-weight: bold\">Share</span> button on the upper right hand corner.  You can either provide an email account\n",
       "or copy the magic link. Users invited by email will need to log into Weights &amp; Biases to view the report. Users who\n",
       "are given a magic link to not need to log into Weights &amp; Biases to view the report.                                \n",
       "\n",
       "Shared reports are view-only.                                                                                      \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
       "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
       "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
       "on:                                                                                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how realistic is that this question will come from a real user one day?                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>is this question about W&amp;B?                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>can the question be answered using the W&amp;B document fragment above?                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>impersonating them! Use exactly the following format: CONTEXT: QUESTION: ANSWER: Let's start!                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "how do I use the n Weights & Biases LangChain integration? How can I log and visualize time series data in WandB? I\n",
       "am logging the score of my LightGBM regression model by doing \u001b[1;36;40mwandb.log({'dev_score': dev_score})\u001b[0m. The problem is  \n",
       "that it is logged as a chart with step-score x-y axes, and I only want the scalar value. As I do not have steps, it\n",
       "is difficult to visualize the score. How can I add a Scalar chart instead?                                         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "In the next step, you will read a fragment of W&B documentation. This will serve as inspiration for synthetic user \n",
       "question and the source of the answer. Here is the document fragment:                                              \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "\n",
       "               \u001b[1;4mdescription: Collaborate and share W&B Reports with peers, co-workers, and your team.\u001b[0m               \n",
       "\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃                                             \u001b[1mCollaborate on reports\u001b[0m                                              ┃\n",
       "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
       "\n",
       "\n",
       "Once you have saved a report, you can select the \u001b[1mShare\u001b[0m button to collaborate. A draft copy of the report is created\n",
       "when you select the \u001b[1mEdit\u001b[0m button. Draft reports auto-save. Select \u001b[1mSave to report\u001b[0m to publish your changes to the     \n",
       "shared report.                                                                                                     \n",
       "\n",
       "A warning notification will appear if an edit conflict occurs. This can occur if you and another collaborator edit \n",
       "the same report at the same time. The warning notification will guide you to resolve potential edit conflicts.     \n",
       "\n",
       "🌆 \u001b]8;id=84265;@site/static/images/reports/share-report.gif\u001b\\Report sharing modal for a report in a 'Public' project\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "                                                \u001b[1mComment on reports\u001b[0m                                                 \n",
       "\n",
       "Click the comment button on a panel in a report to add a comment directly to that panel.                           \n",
       "\n",
       "🌆 \u001b]8;id=171764;/images/reports/demo_comment_on_panels_in_reports.gif\u001b\\Adding a comment to a panel\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "                                          \u001b[1mWho can edit and share reports?\u001b[0m                                          \n",
       "\n",
       "Reports that are created within an individual's private project is only visible to that user. The user can share   \n",
       "their project to a team or to the public.                                                                          \n",
       "\n",
       "On team projects, both the administrator, or member who created the report, can toggle permissions between edit or \n",
       "view access for other team members. Team members can share reports.                                                \n",
       "\n",
       "To share a report, select the \u001b[1mShare\u001b[0m button on the upper right hand corner.  You can either provide an email account\n",
       "or copy the magic link. Users invited by email will need to log into Weights & Biases to view the report. Users who\n",
       "are given a magic link to not need to log into Weights & Biases to view the report.                                \n",
       "\n",
       "Shared reports are view-only.                                                                                      \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
       "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
       "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
       "on:                                                                                                                \n",
       "\n",
       "\u001b[1;33m • \u001b[0mhow realistic is that this question will come from a real user one day?                                         \n",
       "\u001b[1;33m • \u001b[0mis this question about W&B?                                                                                     \n",
       "\u001b[1;33m • \u001b[0mcan the question be answered using the W&B document fragment above?                                             \n",
       "\u001b[1;33m • \u001b[0mhow accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
       "\u001b[1;33m   \u001b[0mimpersonating them! Use exactly the following format: CONTEXT: QUESTION: ANSWER: Let's start!                   \n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(documents, n_questions=3, n_generations=5):\n",
    "    questions = []\n",
    "    for _, document in documents:\n",
    "        chunk = extract_random_chunk(document)\n",
    "        user_prompt = generate_context_prompt(chunk, n_questions)\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': user_prompt}\n",
    "        ]\n",
    "        response = completion_with_backoff(\n",
    "            model=MODEL,\n",
    "            messages = messages,\n",
    "            n = n_generations\n",
    "        )\n",
    "        questions.extend([response.choices[i].message.content for i in range(n_generations)])\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Note about the system role: For GPT4 based pipelines you probably want to move some part of the context prompt to the system context. As we are using gpt-3.5-turbo here, you can put the instruction on the user prompt, you can read more about this on [OpenAI docs here](https://platform.openai.com/docs/guides/chat-completions/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to parse model generation and extract CONTEXT, QUESTION and ANSWER\n",
    "def parse_generation(generation):\n",
    "    lines = generation.split('\\n\\n')\n",
    "    context = []\n",
    "    question = []\n",
    "    answer = []\n",
    "\n",
    "    for line in lines:\n",
    "        if 'CONTEXT:' in line:\n",
    "            context_pattern = re.compile(r'^\\s*\\*{0,2}CONTEXT:?\\*{0,2}:?\\s*')\n",
    "            line = context_pattern.sub('', line).strip()\n",
    "            context.append(line)\n",
    "        elif 'QUESTION:' in line:\n",
    "            question_pattern = re.compile(r'^\\s*\\*{0,2}QUESTION:?\\*{0,2}:?\\s*')\n",
    "            line = question_pattern.sub('', line).strip()\n",
    "            question.append(line)\n",
    "        elif 'ANSWER:' in line:\n",
    "            answer_pattern = re.compile(r'^\\s*\\*{0,2}ANSWER:?\\*{0,2}:?\\s*')\n",
    "            line = answer_pattern.sub('', line).strip()\n",
    "            answer.append(line)\n",
    "    \n",
    "    context = '\\n'.join(context)\n",
    "    question = '\\n'.join(question)\n",
    "    answer = '\\n'.join(answer)\n",
    "    return context, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = generate_questions([documents[0]], n_questions=3, n_generations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A user is working on a collaborative project using Weights & Biases and is interested in sharing reports with team members or the public. They want to understand the process of sharing reports and managing permissions within team projects.',\n",
       " 'How can I share a report in Weights & Biases and manage permissions within team projects?',\n",
       " \"To share a report in Weights & Biases, you can select the **Share** button located in the upper right-hand corner of the report. From there, you have the option to provide an email account for invitation or copy a magic link. Users invited by email will need to log into Weights & Biases to view the report, while users given a magic link do not need to log in. Reports created within an individual's private project are only visible to that user until shared with a team or made public. In team projects, both the administrator and the member who created the report can toggle permissions between edit or view access for other team members. Team members with access can also share reports.\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_generation(generations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = generate_questions(documents, n_questions=3, n_generations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact generated_examples>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_generations = []\n",
    "for generation in generations:\n",
    "    context, question, answer = parse_generation(generation)\n",
    "    parsed_generations.append({'context': context, 'question': question, 'answer': answer})\n",
    "\n",
    "# let's convert parsed_generations to a pandas dataframe and save it locally\n",
    "df = pd.DataFrame(parsed_generations)\n",
    "csv_path = '../files/generated_examples.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "# log df as a table to W&B for inter\n",
    "wandb.log({'generated_examples': wandb.Table(dataframe=df)})\n",
    "\n",
    "# log csv file as an artifact to W&B for later use\n",
    "# artifact is a dataset and model versioning tool\n",
    "artifact = wandb.Artifact('generated_examples', type='dataset')\n",
    "artifact.add_file(csv_path)\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-violet-44</strong> at: <a href='https://wandb.ai/mary1378/llmapps/runs/v8xppo89' target=\"_blank\">https://wandb.ai/mary1378/llmapps/runs/v8xppo89</a><br/> View project at: <a href='https://wandb.ai/mary1378/llmapps' target=\"_blank\">https://wandb.ai/mary1378/llmapps</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240808_104653-v8xppo89\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
